{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the MANN Package to train a Fully Connected Neural Network\n",
    "\n",
    "In this notebook, the MANN package will be used to train pruned fully connected neural networks.  We will train two single-task networks on two separate tasks and one multitask network which performs both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MANN package and TensorFlow\n",
    "import tensorflow as tf\n",
    "import mann\n",
    "\n",
    "# Load the make_classification function from scikit-learn\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use two separate generated datasets\n",
    "x1, y1 = make_classification(\n",
    "    n_samples = 10000,\n",
    "    n_features = 10,\n",
    "    n_informative = 8,\n",
    "    n_classes = 2,\n",
    "    n_clusters_per_class = 1\n",
    ")\n",
    "\n",
    "x2, y2 = make_classification(\n",
    "    n_samples = 10000,\n",
    "    n_features = 20,\n",
    "    n_informative = 13,\n",
    "    n_classes = 10,\n",
    "    n_clusters_per_class = 1\n",
    ")\n",
    "\n",
    "# Flatten the outputs for simplicity\n",
    "y1 = y1.reshape(-1, 1)\n",
    "y2 = y2.reshape(-1, 1)\n",
    "\n",
    "# Create a callback to stop training early\n",
    "callback = tf.keras.callbacks.EarlyStopping(min_delta = 0.01, patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the first model\n",
    "\n",
    "This first model is a fully connected model which will perform the first task. It will be pruned utilizing the MANN package so that most of its weights are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:24:33.181999: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-09 08:24:33.182119: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# After data generation, create the single-task model using the TensorFlow Keras Functional API\n",
    "input_layer = tf.keras.Input(x1.shape[-1])\n",
    "\n",
    "# Instead of using keras Dense Layers, use MANN MaskedDense Layers\n",
    "x = mann.layers.MaskedDense(\n",
    "    100,\n",
    "    activation = 'relu'\n",
    ")(input_layer)\n",
    "\n",
    "for _ in range(5):\n",
    "    x = mann.layers.MaskedDense(\n",
    "        100,\n",
    "        activation = 'relu'\n",
    "    )(x)\n",
    "\n",
    "# Create the output layer as another MANN MaskedDense Layer\n",
    "output_layer = mann.layers.MaskedDense(1, activation = 'sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model for training and masking\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Mask (prune) the model using the MANN package\n",
    "model = mann.utils.mask_model(\n",
    "    model = model,              # The model to be pruned\n",
    "    percentile = 90,            # The percentile to be masked, for example, if the value is 90, then 90% of weights will be masked\n",
    "    method = 'gradients',       # The method to use to mask, either 'gradients' or 'magnitude'\n",
    "    exclusive = True,           # Whether weight locations must be exclusive to each task\n",
    "    x = x1[:2000],              # The input data\n",
    "    y = y1[:2000]               # The expected outputs\n",
    ")\n",
    "\n",
    "# Recompile the model\n",
    "model.compile(\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.90325785e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -2.18045320e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "        -1.02299631e-01,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -6.97451178e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  1.79088693e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -7.33782649e-02,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  7.08636120e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  6.00530319e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  2.24886984e-02,\n",
       "        -0.00000000e+00, -0.00000000e+00,  4.43924144e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  8.40805694e-02,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -1.07569598e-01,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  4.97884564e-02, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -3.77398208e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00],\n",
       "       [ 0.00000000e+00,  3.83946709e-02,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -1.02027036e-01, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -6.85307607e-02,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         1.07563017e-02,  0.00000000e+00,  3.31555828e-02,\n",
       "         0.00000000e+00,  9.21334978e-03, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  2.45478246e-02, -4.32474762e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -4.29191291e-02,\n",
       "        -0.00000000e+00,  3.84518993e-03,  0.00000000e+00,\n",
       "        -7.80737121e-03,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -7.25991875e-02,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -5.94532080e-02, -4.49520387e-02,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  1.97161585e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00, -5.66341951e-02,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -2.46081613e-02,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 9.57005173e-02, -1.77818374e-03,  0.00000000e+00,\n",
       "         7.66643584e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  5.48080765e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -1.41937109e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         6.10504225e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  1.08361626e-02, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  3.81303728e-02,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -3.95257249e-02,  0.00000000e+00,\n",
       "        -0.00000000e+00],\n",
       "       [-8.91938731e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "        -7.54843131e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         1.04577793e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -3.32953036e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -9.17289779e-02,\n",
       "         0.00000000e+00, -5.20309294e-03,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  2.40860018e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  6.77720457e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  7.95910060e-02, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -6.70844242e-02,  0.00000000e+00,  3.87037247e-02,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -1.22131400e-01, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         7.79403234e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.45932540e-01,  0.00000000e+00, -4.46709469e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.02376693e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.02565473e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -5.32292426e-02,  0.00000000e+00,\n",
       "        -0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         3.60406153e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         1.21219316e-03, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         8.93686190e-02,  0.00000000e+00,  2.63989456e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -3.09454333e-02,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -3.76900882e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -2.02683117e-02, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         6.47672340e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -1.74746979e-02,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -4.96198563e-03,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         8.91530737e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "         1.00252084e-01, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -1.71067342e-02,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -9.38432887e-02,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -8.98185931e-03, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -3.80685786e-03,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -6.39520288e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00],\n",
       "       [-0.00000000e+00, -5.42603508e-02, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         6.50550872e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -2.47339830e-02,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -7.60391355e-02, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -1.13054931e-01,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-0.00000000e+00, -4.18215282e-02, -3.66207808e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  3.98095362e-02, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  3.86240557e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -9.17036608e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         2.40714033e-03, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -7.57613918e-03,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         3.61052318e-03,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  1.06740734e-02, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00],\n",
       "       [-0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         7.04010278e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "        -7.04432884e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  1.61672570e-02,\n",
       "        -0.00000000e+00,  1.93902664e-02,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  4.66009462e-03,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  6.54654726e-02,\n",
       "         0.00000000e+00,  2.06907168e-02, -0.00000000e+00,\n",
       "         3.52003917e-05, -0.00000000e+00, -0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00, -3.93262208e-02, -3.19207311e-02,\n",
       "        -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        -0.00000000e+00,  0.00000000e+00, -4.12450230e-04,\n",
       "        -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To show how the layers of the model have been pruned, output the kernel of the first MaskedDense Layer\n",
    "model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:26:35.223779: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-09 08:26:35.224169: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2021-11-09 08:26:35.420391: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "63/63 [==============================] - 2s 10ms/step - loss: 0.6903 - accuracy: 0.5299 - val_loss: 0.6650 - val_accuracy: 0.7810\n",
      "Epoch 2/100\n",
      " 1/63 [..............................] - ETA: 0s - loss: 0.6668 - accuracy: 0.7422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:26:36.874633: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 6ms/step - loss: 0.4524 - accuracy: 0.8561 - val_loss: 0.2396 - val_accuracy: 0.9075\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.2254 - accuracy: 0.9100 - val_loss: 0.1915 - val_accuracy: 0.9285\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1987 - accuracy: 0.9203 - val_loss: 0.1747 - val_accuracy: 0.9310\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1819 - accuracy: 0.9298 - val_loss: 0.1584 - val_accuracy: 0.9395\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1599 - accuracy: 0.9389 - val_loss: 0.1336 - val_accuracy: 0.9535\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1347 - accuracy: 0.9518 - val_loss: 0.1042 - val_accuracy: 0.9685\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.1110 - accuracy: 0.9644 - val_loss: 0.0865 - val_accuracy: 0.9745\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0917 - accuracy: 0.9735 - val_loss: 0.0714 - val_accuracy: 0.9800\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0793 - accuracy: 0.9784 - val_loss: 0.0629 - val_accuracy: 0.9825\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0707 - accuracy: 0.9808 - val_loss: 0.0558 - val_accuracy: 0.9855\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0648 - accuracy: 0.9839 - val_loss: 0.0500 - val_accuracy: 0.9855\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0632 - accuracy: 0.9850 - val_loss: 0.0489 - val_accuracy: 0.9870\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.0624 - accuracy: 0.9833 - val_loss: 0.0459 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:26:42.428416: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Model Accuracy: 0.9838\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the first dataset\n",
    "model.fit(x1, y1, batch_size = 128, epochs = 100, validation_split = 0.2, callbacks = [callback])\n",
    "print(f'First Model Accuracy: {((model.predict(x1)>= 0.5).astype(int).flatten() == y1.flatten()).sum()/y1.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the second model\n",
    "\n",
    "This second model is a fully connected model which will perform the second task. It will be pruned utilizing the MANN package so that most of its weights are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the second model\n",
    "input_layer = tf.keras.Input(x2.shape[-1])\n",
    "\n",
    "# Instead of using keras Dense Layers, use MANN MaskedDense Layers\n",
    "x = mann.layers.MaskedDense(\n",
    "    100,\n",
    "    activation = 'relu'\n",
    ")(input_layer)\n",
    "\n",
    "for _ in range(5):\n",
    "    x = mann.layers.MaskedDense(\n",
    "        100,\n",
    "        activation = 'relu'\n",
    "    )(x)\n",
    "\n",
    "# Create the output layer as another MANN MaskedDense Layer\n",
    "output_layer = mann.layers.MaskedDense(10, activation = 'softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:29:35.230061: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/63 [============================>.] - ETA: 0s - loss: 2.2996 - accuracy: 0.1070"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:29:36.506774: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 13ms/step - loss: 2.2993 - accuracy: 0.1073 - val_loss: 2.2719 - val_accuracy: 0.1410\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.2235 - accuracy: 0.1600 - val_loss: 2.1449 - val_accuracy: 0.1795\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 2.1064 - accuracy: 0.1773 - val_loss: 2.0628 - val_accuracy: 0.1975\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 2.0460 - accuracy: 0.1931 - val_loss: 2.0103 - val_accuracy: 0.2240\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.9907 - accuracy: 0.2244 - val_loss: 1.9565 - val_accuracy: 0.2540\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.9345 - accuracy: 0.2633 - val_loss: 1.9224 - val_accuracy: 0.2625\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.8932 - accuracy: 0.2869 - val_loss: 1.8924 - val_accuracy: 0.2655\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.8515 - accuracy: 0.3004 - val_loss: 1.8419 - val_accuracy: 0.3005\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.8042 - accuracy: 0.3259 - val_loss: 1.7916 - val_accuracy: 0.3325\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.7471 - accuracy: 0.3553 - val_loss: 1.7275 - val_accuracy: 0.3700\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.6962 - accuracy: 0.3778 - val_loss: 1.6849 - val_accuracy: 0.3845\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.6484 - accuracy: 0.3960 - val_loss: 1.6362 - val_accuracy: 0.3980\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5996 - accuracy: 0.4134 - val_loss: 1.5852 - val_accuracy: 0.4205\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.5448 - accuracy: 0.4455 - val_loss: 1.5141 - val_accuracy: 0.4625\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4685 - accuracy: 0.4764 - val_loss: 1.4555 - val_accuracy: 0.4760\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.4089 - accuracy: 0.4988 - val_loss: 1.4210 - val_accuracy: 0.4860\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3603 - accuracy: 0.5134 - val_loss: 1.3565 - val_accuracy: 0.5165\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.3221 - accuracy: 0.5299 - val_loss: 1.3343 - val_accuracy: 0.5105\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2919 - accuracy: 0.5441 - val_loss: 1.3034 - val_accuracy: 0.5220\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2574 - accuracy: 0.5534 - val_loss: 1.2744 - val_accuracy: 0.5390\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.2300 - accuracy: 0.5664 - val_loss: 1.2583 - val_accuracy: 0.5465\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1987 - accuracy: 0.5793 - val_loss: 1.2316 - val_accuracy: 0.5590\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1808 - accuracy: 0.5923 - val_loss: 1.2031 - val_accuracy: 0.5725\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1428 - accuracy: 0.6035 - val_loss: 1.1952 - val_accuracy: 0.5770\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.1251 - accuracy: 0.6144 - val_loss: 1.1633 - val_accuracy: 0.5835\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0907 - accuracy: 0.6320 - val_loss: 1.1387 - val_accuracy: 0.5980\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0708 - accuracy: 0.6395 - val_loss: 1.1063 - val_accuracy: 0.6260\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0471 - accuracy: 0.6491 - val_loss: 1.0895 - val_accuracy: 0.6205\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 1.0202 - accuracy: 0.6608 - val_loss: 1.0548 - val_accuracy: 0.6455\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9921 - accuracy: 0.6736 - val_loss: 1.0352 - val_accuracy: 0.6565\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9700 - accuracy: 0.6829 - val_loss: 1.0143 - val_accuracy: 0.6670\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 0.9538 - accuracy: 0.6860 - val_loss: 0.9948 - val_accuracy: 0.6660\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9345 - accuracy: 0.6929 - val_loss: 0.9752 - val_accuracy: 0.6805\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9163 - accuracy: 0.7008 - val_loss: 0.9649 - val_accuracy: 0.6835\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.9011 - accuracy: 0.7055 - val_loss: 0.9527 - val_accuracy: 0.6780\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8858 - accuracy: 0.7096 - val_loss: 0.9321 - val_accuracy: 0.6860\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8752 - accuracy: 0.7173 - val_loss: 0.9299 - val_accuracy: 0.6915\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8617 - accuracy: 0.7170 - val_loss: 0.9065 - val_accuracy: 0.7070\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8524 - accuracy: 0.7183 - val_loss: 0.9341 - val_accuracy: 0.6805\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8398 - accuracy: 0.7264 - val_loss: 0.9189 - val_accuracy: 0.6925\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8246 - accuracy: 0.7319 - val_loss: 0.8809 - val_accuracy: 0.7090\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 0s 6ms/step - loss: 0.8174 - accuracy: 0.7336 - val_loss: 0.8785 - val_accuracy: 0.7135\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.8022 - accuracy: 0.7399 - val_loss: 0.8788 - val_accuracy: 0.7090\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7939 - accuracy: 0.7409 - val_loss: 0.8539 - val_accuracy: 0.7205\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7896 - accuracy: 0.7419 - val_loss: 0.8479 - val_accuracy: 0.7315\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7752 - accuracy: 0.7493 - val_loss: 0.8467 - val_accuracy: 0.7255\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7653 - accuracy: 0.7503 - val_loss: 0.8422 - val_accuracy: 0.7285\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7607 - accuracy: 0.7556 - val_loss: 0.8293 - val_accuracy: 0.7305\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7508 - accuracy: 0.7510 - val_loss: 0.8164 - val_accuracy: 0.7355\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7358 - accuracy: 0.7604 - val_loss: 0.8139 - val_accuracy: 0.7365\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7323 - accuracy: 0.7653 - val_loss: 0.8106 - val_accuracy: 0.7375\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7226 - accuracy: 0.7695 - val_loss: 0.7998 - val_accuracy: 0.7345\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7250 - accuracy: 0.7643 - val_loss: 0.8045 - val_accuracy: 0.7325\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7126 - accuracy: 0.7695 - val_loss: 0.7962 - val_accuracy: 0.7435\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 0s 7ms/step - loss: 0.7066 - accuracy: 0.7713 - val_loss: 0.7960 - val_accuracy: 0.7385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:30:00.912786: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Model Accuracy: 0.7609\n"
     ]
    }
   ],
   "source": [
    "# Repeat the pruning process for the second model\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n",
    "\n",
    "model = mann.utils.mask_model(\n",
    "    model = model,\n",
    "    percentile = 90,\n",
    "    method = 'gradients',\n",
    "    exclusive = True,\n",
    "    x = x2[:2000],\n",
    "    y = y2.reshape(-1, 1)[:2000]\n",
    ")\n",
    "\n",
    "model.compile(loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')\n",
    "\n",
    "model.fit(x2, y2, epochs = 100, batch_size = 128, validation_split = 0.2, callbacks = [callback])\n",
    "\n",
    "print(f'Second Model Accuracy: {(model.predict(x2).argmax(axis = 1) == y2.flatten()).astype(int).sum()/y2.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the MANN\n",
    "\n",
    "The third and final model we create here will be a multitask model (MANN) which performs both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:30:02.951589: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - ETA: 0s - loss: 2.9672 - masked_dense_16_loss: 0.6649 - masked_dense_17_loss: 2.3023 - masked_dense_16_accuracy: 0.5364 - masked_dense_17_accuracy: 0.1153"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:30:05.056296: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 27ms/step - loss: 2.9672 - masked_dense_16_loss: 0.6649 - masked_dense_17_loss: 2.3023 - masked_dense_16_accuracy: 0.5364 - masked_dense_17_accuracy: 0.1153 - val_loss: 2.8330 - val_masked_dense_16_loss: 0.5336 - val_masked_dense_17_loss: 2.2994 - val_masked_dense_16_accuracy: 0.7080 - val_masked_dense_17_accuracy: 0.1515\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.7088 - masked_dense_16_loss: 0.4750 - masked_dense_17_loss: 2.2338 - masked_dense_16_accuracy: 0.8455 - masked_dense_17_accuracy: 0.1543 - val_loss: 2.6430 - val_masked_dense_16_loss: 0.4385 - val_masked_dense_17_loss: 2.2046 - val_masked_dense_16_accuracy: 0.8975 - val_masked_dense_17_accuracy: 0.1740\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.5521 - masked_dense_16_loss: 0.4144 - masked_dense_17_loss: 2.1377 - masked_dense_16_accuracy: 0.9056 - masked_dense_17_accuracy: 0.1779 - val_loss: 2.4594 - val_masked_dense_16_loss: 0.3784 - val_masked_dense_17_loss: 2.0811 - val_masked_dense_16_accuracy: 0.9270 - val_masked_dense_17_accuracy: 0.2150\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.3456 - masked_dense_16_loss: 0.3312 - masked_dense_17_loss: 2.0145 - masked_dense_16_accuracy: 0.9258 - masked_dense_17_accuracy: 0.2473 - val_loss: 2.2312 - val_masked_dense_16_loss: 0.2603 - val_masked_dense_17_loss: 1.9708 - val_masked_dense_16_accuracy: 0.9370 - val_masked_dense_17_accuracy: 0.2755\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 2.1200 - masked_dense_16_loss: 0.2051 - masked_dense_17_loss: 1.9149 - masked_dense_16_accuracy: 0.9379 - masked_dense_17_accuracy: 0.2879 - val_loss: 2.0475 - val_masked_dense_16_loss: 0.1446 - val_masked_dense_17_loss: 1.9029 - val_masked_dense_16_accuracy: 0.9540 - val_masked_dense_17_accuracy: 0.2905\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.9725 - masked_dense_16_loss: 0.1275 - masked_dense_17_loss: 1.8451 - masked_dense_16_accuracy: 0.9606 - masked_dense_17_accuracy: 0.3060 - val_loss: 1.9505 - val_masked_dense_16_loss: 0.0974 - val_masked_dense_17_loss: 1.8532 - val_masked_dense_16_accuracy: 0.9690 - val_masked_dense_17_accuracy: 0.3025\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.8969 - masked_dense_16_loss: 0.1012 - masked_dense_17_loss: 1.7957 - masked_dense_16_accuracy: 0.9701 - masked_dense_17_accuracy: 0.3234 - val_loss: 1.8904 - val_masked_dense_16_loss: 0.0808 - val_masked_dense_17_loss: 1.8096 - val_masked_dense_16_accuracy: 0.9750 - val_masked_dense_17_accuracy: 0.3205\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.8326 - masked_dense_16_loss: 0.0916 - masked_dense_17_loss: 1.7411 - masked_dense_16_accuracy: 0.9741 - masked_dense_17_accuracy: 0.3516 - val_loss: 1.8479 - val_masked_dense_16_loss: 0.0758 - val_masked_dense_17_loss: 1.7721 - val_masked_dense_16_accuracy: 0.9790 - val_masked_dense_17_accuracy: 0.3540\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.7628 - masked_dense_16_loss: 0.0830 - masked_dense_17_loss: 1.6798 - masked_dense_16_accuracy: 0.9754 - masked_dense_17_accuracy: 0.3869 - val_loss: 1.7677 - val_masked_dense_16_loss: 0.0662 - val_masked_dense_17_loss: 1.7015 - val_masked_dense_16_accuracy: 0.9805 - val_masked_dense_17_accuracy: 0.3900\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.7090 - masked_dense_16_loss: 0.0771 - masked_dense_17_loss: 1.6319 - masked_dense_16_accuracy: 0.9776 - masked_dense_17_accuracy: 0.4035 - val_loss: 1.7585 - val_masked_dense_16_loss: 0.0645 - val_masked_dense_17_loss: 1.6940 - val_masked_dense_16_accuracy: 0.9805 - val_masked_dense_17_accuracy: 0.3835\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6692 - masked_dense_16_loss: 0.0733 - masked_dense_17_loss: 1.5959 - masked_dense_16_accuracy: 0.9785 - masked_dense_17_accuracy: 0.4191 - val_loss: 1.6849 - val_masked_dense_16_loss: 0.0592 - val_masked_dense_17_loss: 1.6257 - val_masked_dense_16_accuracy: 0.9815 - val_masked_dense_17_accuracy: 0.4150\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.6304 - masked_dense_16_loss: 0.0708 - masked_dense_17_loss: 1.5597 - masked_dense_16_accuracy: 0.9811 - masked_dense_17_accuracy: 0.4349 - val_loss: 1.6623 - val_masked_dense_16_loss: 0.0570 - val_masked_dense_17_loss: 1.6053 - val_masked_dense_16_accuracy: 0.9840 - val_masked_dense_17_accuracy: 0.4220\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.5856 - masked_dense_16_loss: 0.0685 - masked_dense_17_loss: 1.5172 - masked_dense_16_accuracy: 0.9811 - masked_dense_17_accuracy: 0.4561 - val_loss: 1.6065 - val_masked_dense_16_loss: 0.0568 - val_masked_dense_17_loss: 1.5497 - val_masked_dense_16_accuracy: 0.9835 - val_masked_dense_17_accuracy: 0.4455\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 1.5480 - masked_dense_16_loss: 0.0662 - masked_dense_17_loss: 1.4818 - masked_dense_16_accuracy: 0.9833 - masked_dense_17_accuracy: 0.4739 - val_loss: 1.5735 - val_masked_dense_16_loss: 0.0541 - val_masked_dense_17_loss: 1.5193 - val_masked_dense_16_accuracy: 0.9860 - val_masked_dense_17_accuracy: 0.4560\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 1.5061 - masked_dense_16_loss: 0.0643 - masked_dense_17_loss: 1.4418 - masked_dense_16_accuracy: 0.9824 - masked_dense_17_accuracy: 0.4939 - val_loss: 1.5181 - val_masked_dense_16_loss: 0.0523 - val_masked_dense_17_loss: 1.4659 - val_masked_dense_16_accuracy: 0.9870 - val_masked_dense_17_accuracy: 0.4890\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.4599 - masked_dense_16_loss: 0.0624 - masked_dense_17_loss: 1.3975 - masked_dense_16_accuracy: 0.9846 - masked_dense_17_accuracy: 0.5166 - val_loss: 1.4745 - val_masked_dense_16_loss: 0.0562 - val_masked_dense_17_loss: 1.4183 - val_masked_dense_16_accuracy: 0.9860 - val_masked_dense_17_accuracy: 0.5105\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.4029 - masked_dense_16_loss: 0.0611 - masked_dense_17_loss: 1.3418 - masked_dense_16_accuracy: 0.9856 - masked_dense_17_accuracy: 0.5468 - val_loss: 1.4187 - val_masked_dense_16_loss: 0.0506 - val_masked_dense_17_loss: 1.3681 - val_masked_dense_16_accuracy: 0.9855 - val_masked_dense_17_accuracy: 0.5375\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.3482 - masked_dense_16_loss: 0.0627 - masked_dense_17_loss: 1.2855 - masked_dense_16_accuracy: 0.9836 - masked_dense_17_accuracy: 0.5771 - val_loss: 1.3527 - val_masked_dense_16_loss: 0.0501 - val_masked_dense_17_loss: 1.3025 - val_masked_dense_16_accuracy: 0.9855 - val_masked_dense_17_accuracy: 0.5655\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.2987 - masked_dense_16_loss: 0.0583 - masked_dense_17_loss: 1.2404 - masked_dense_16_accuracy: 0.9860 - masked_dense_17_accuracy: 0.5911 - val_loss: 1.2940 - val_masked_dense_16_loss: 0.0488 - val_masked_dense_17_loss: 1.2453 - val_masked_dense_16_accuracy: 0.9875 - val_masked_dense_17_accuracy: 0.5740\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.2497 - masked_dense_16_loss: 0.0569 - masked_dense_17_loss: 1.1928 - masked_dense_16_accuracy: 0.9863 - masked_dense_17_accuracy: 0.6001 - val_loss: 1.2845 - val_masked_dense_16_loss: 0.0491 - val_masked_dense_17_loss: 1.2354 - val_masked_dense_16_accuracy: 0.9865 - val_masked_dense_17_accuracy: 0.5790\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.2206 - masked_dense_16_loss: 0.0558 - masked_dense_17_loss: 1.1648 - masked_dense_16_accuracy: 0.9866 - masked_dense_17_accuracy: 0.6168 - val_loss: 1.2375 - val_masked_dense_16_loss: 0.0469 - val_masked_dense_17_loss: 1.1905 - val_masked_dense_16_accuracy: 0.9885 - val_masked_dense_17_accuracy: 0.5925\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.1790 - masked_dense_16_loss: 0.0537 - masked_dense_17_loss: 1.1253 - masked_dense_16_accuracy: 0.9879 - masked_dense_17_accuracy: 0.6304 - val_loss: 1.1925 - val_masked_dense_16_loss: 0.0471 - val_masked_dense_17_loss: 1.1454 - val_masked_dense_16_accuracy: 0.9880 - val_masked_dense_17_accuracy: 0.6140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.1522 - masked_dense_16_loss: 0.0536 - masked_dense_17_loss: 1.0986 - masked_dense_16_accuracy: 0.9875 - masked_dense_17_accuracy: 0.6391 - val_loss: 1.1659 - val_masked_dense_16_loss: 0.0476 - val_masked_dense_17_loss: 1.1183 - val_masked_dense_16_accuracy: 0.9885 - val_masked_dense_17_accuracy: 0.6290\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.1225 - masked_dense_16_loss: 0.0521 - masked_dense_17_loss: 1.0704 - masked_dense_16_accuracy: 0.9879 - masked_dense_17_accuracy: 0.6488 - val_loss: 1.1449 - val_masked_dense_16_loss: 0.0453 - val_masked_dense_17_loss: 1.0996 - val_masked_dense_16_accuracy: 0.9890 - val_masked_dense_17_accuracy: 0.6330\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.0979 - masked_dense_16_loss: 0.0517 - masked_dense_17_loss: 1.0462 - masked_dense_16_accuracy: 0.9879 - masked_dense_17_accuracy: 0.6538 - val_loss: 1.1154 - val_masked_dense_16_loss: 0.0452 - val_masked_dense_17_loss: 1.0703 - val_masked_dense_16_accuracy: 0.9905 - val_masked_dense_17_accuracy: 0.6385\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.0765 - masked_dense_16_loss: 0.0519 - masked_dense_17_loss: 1.0246 - masked_dense_16_accuracy: 0.9879 - masked_dense_17_accuracy: 0.6620 - val_loss: 1.0951 - val_masked_dense_16_loss: 0.0455 - val_masked_dense_17_loss: 1.0497 - val_masked_dense_16_accuracy: 0.9895 - val_masked_dense_17_accuracy: 0.6470\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.0537 - masked_dense_16_loss: 0.0513 - masked_dense_17_loss: 1.0024 - masked_dense_16_accuracy: 0.9878 - masked_dense_17_accuracy: 0.6669 - val_loss: 1.1084 - val_masked_dense_16_loss: 0.0486 - val_masked_dense_17_loss: 1.0599 - val_masked_dense_16_accuracy: 0.9870 - val_masked_dense_17_accuracy: 0.6530\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.0384 - masked_dense_16_loss: 0.0498 - masked_dense_17_loss: 0.9886 - masked_dense_16_accuracy: 0.9885 - masked_dense_17_accuracy: 0.6764 - val_loss: 1.0596 - val_masked_dense_16_loss: 0.0423 - val_masked_dense_17_loss: 1.0173 - val_masked_dense_16_accuracy: 0.9905 - val_masked_dense_17_accuracy: 0.6565\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 1.0128 - masked_dense_16_loss: 0.0486 - masked_dense_17_loss: 0.9642 - masked_dense_16_accuracy: 0.9891 - masked_dense_17_accuracy: 0.6829 - val_loss: 1.0462 - val_masked_dense_16_loss: 0.0420 - val_masked_dense_17_loss: 1.0042 - val_masked_dense_16_accuracy: 0.9915 - val_masked_dense_17_accuracy: 0.6640\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.9956 - masked_dense_16_loss: 0.0487 - masked_dense_17_loss: 0.9469 - masked_dense_16_accuracy: 0.9886 - masked_dense_17_accuracy: 0.6861 - val_loss: 1.0281 - val_masked_dense_16_loss: 0.0430 - val_masked_dense_17_loss: 0.9852 - val_masked_dense_16_accuracy: 0.9875 - val_masked_dense_17_accuracy: 0.6725\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.9847 - masked_dense_16_loss: 0.0503 - masked_dense_17_loss: 0.9344 - masked_dense_16_accuracy: 0.9878 - masked_dense_17_accuracy: 0.6924 - val_loss: 1.0324 - val_masked_dense_16_loss: 0.0428 - val_masked_dense_17_loss: 0.9896 - val_masked_dense_16_accuracy: 0.9885 - val_masked_dense_17_accuracy: 0.6735\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 17ms/step - loss: 0.9655 - masked_dense_16_loss: 0.0476 - masked_dense_17_loss: 0.9180 - masked_dense_16_accuracy: 0.9885 - masked_dense_17_accuracy: 0.7009 - val_loss: 1.0104 - val_masked_dense_16_loss: 0.0464 - val_masked_dense_17_loss: 0.9639 - val_masked_dense_16_accuracy: 0.9890 - val_masked_dense_17_accuracy: 0.6730\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.9491 - masked_dense_16_loss: 0.0479 - masked_dense_17_loss: 0.9012 - masked_dense_16_accuracy: 0.9901 - masked_dense_17_accuracy: 0.7038 - val_loss: 1.0070 - val_masked_dense_16_loss: 0.0427 - val_masked_dense_17_loss: 0.9644 - val_masked_dense_16_accuracy: 0.9915 - val_masked_dense_17_accuracy: 0.6805\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.9342 - masked_dense_16_loss: 0.0470 - masked_dense_17_loss: 0.8873 - masked_dense_16_accuracy: 0.9898 - masked_dense_17_accuracy: 0.7109 - val_loss: 0.9832 - val_masked_dense_16_loss: 0.0415 - val_masked_dense_17_loss: 0.9417 - val_masked_dense_16_accuracy: 0.9895 - val_masked_dense_17_accuracy: 0.6905\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.9234 - masked_dense_16_loss: 0.0450 - masked_dense_17_loss: 0.8784 - masked_dense_16_accuracy: 0.9904 - masked_dense_17_accuracy: 0.7125 - val_loss: 0.9589 - val_masked_dense_16_loss: 0.0423 - val_masked_dense_17_loss: 0.9167 - val_masked_dense_16_accuracy: 0.9895 - val_masked_dense_17_accuracy: 0.6950\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.9153 - masked_dense_16_loss: 0.0475 - masked_dense_17_loss: 0.8677 - masked_dense_16_accuracy: 0.9886 - masked_dense_17_accuracy: 0.7181 - val_loss: 0.9534 - val_masked_dense_16_loss: 0.0421 - val_masked_dense_17_loss: 0.9113 - val_masked_dense_16_accuracy: 0.9900 - val_masked_dense_17_accuracy: 0.6930\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.9041 - masked_dense_16_loss: 0.0449 - masked_dense_17_loss: 0.8592 - masked_dense_16_accuracy: 0.9904 - masked_dense_17_accuracy: 0.7171 - val_loss: 0.9448 - val_masked_dense_16_loss: 0.0436 - val_masked_dense_17_loss: 0.9012 - val_masked_dense_16_accuracy: 0.9890 - val_masked_dense_17_accuracy: 0.6995\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8837 - masked_dense_16_loss: 0.0444 - masked_dense_17_loss: 0.8393 - masked_dense_16_accuracy: 0.9906 - masked_dense_17_accuracy: 0.7248 - val_loss: 0.9259 - val_masked_dense_16_loss: 0.0408 - val_masked_dense_17_loss: 0.8851 - val_masked_dense_16_accuracy: 0.9905 - val_masked_dense_17_accuracy: 0.7035\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8731 - masked_dense_16_loss: 0.0430 - masked_dense_17_loss: 0.8301 - masked_dense_16_accuracy: 0.9905 - masked_dense_17_accuracy: 0.7270 - val_loss: 0.9180 - val_masked_dense_16_loss: 0.0417 - val_masked_dense_17_loss: 0.8762 - val_masked_dense_16_accuracy: 0.9900 - val_masked_dense_17_accuracy: 0.7105\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8584 - masked_dense_16_loss: 0.0433 - masked_dense_17_loss: 0.8152 - masked_dense_16_accuracy: 0.9909 - masked_dense_17_accuracy: 0.7353 - val_loss: 0.9178 - val_masked_dense_16_loss: 0.0412 - val_masked_dense_17_loss: 0.8766 - val_masked_dense_16_accuracy: 0.9905 - val_masked_dense_17_accuracy: 0.7110\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8541 - masked_dense_16_loss: 0.0428 - masked_dense_17_loss: 0.8114 - masked_dense_16_accuracy: 0.9905 - masked_dense_17_accuracy: 0.7353 - val_loss: 0.9037 - val_masked_dense_16_loss: 0.0406 - val_masked_dense_17_loss: 0.8631 - val_masked_dense_16_accuracy: 0.9895 - val_masked_dense_17_accuracy: 0.7130\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8407 - masked_dense_16_loss: 0.0427 - masked_dense_17_loss: 0.7979 - masked_dense_16_accuracy: 0.9910 - masked_dense_17_accuracy: 0.7405 - val_loss: 0.9012 - val_masked_dense_16_loss: 0.0411 - val_masked_dense_17_loss: 0.8601 - val_masked_dense_16_accuracy: 0.9900 - val_masked_dense_17_accuracy: 0.7190\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8245 - masked_dense_16_loss: 0.0420 - masked_dense_17_loss: 0.7825 - masked_dense_16_accuracy: 0.9908 - masked_dense_17_accuracy: 0.7444 - val_loss: 0.8958 - val_masked_dense_16_loss: 0.0421 - val_masked_dense_17_loss: 0.8537 - val_masked_dense_16_accuracy: 0.9890 - val_masked_dense_17_accuracy: 0.7155\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8155 - masked_dense_16_loss: 0.0423 - masked_dense_17_loss: 0.7732 - masked_dense_16_accuracy: 0.9906 - masked_dense_17_accuracy: 0.7480 - val_loss: 0.8745 - val_masked_dense_16_loss: 0.0387 - val_masked_dense_17_loss: 0.8358 - val_masked_dense_16_accuracy: 0.9915 - val_masked_dense_17_accuracy: 0.7240\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8128 - masked_dense_16_loss: 0.0418 - masked_dense_17_loss: 0.7710 - masked_dense_16_accuracy: 0.9904 - masked_dense_17_accuracy: 0.7465 - val_loss: 0.8796 - val_masked_dense_16_loss: 0.0393 - val_masked_dense_17_loss: 0.8404 - val_masked_dense_16_accuracy: 0.9910 - val_masked_dense_17_accuracy: 0.7200\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.8008 - masked_dense_16_loss: 0.0409 - masked_dense_17_loss: 0.7599 - masked_dense_16_accuracy: 0.9913 - masked_dense_17_accuracy: 0.7548 - val_loss: 0.8633 - val_masked_dense_16_loss: 0.0393 - val_masked_dense_17_loss: 0.8240 - val_masked_dense_16_accuracy: 0.9905 - val_masked_dense_17_accuracy: 0.7315\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7901 - masked_dense_16_loss: 0.0405 - masked_dense_17_loss: 0.7497 - masked_dense_16_accuracy: 0.9914 - masked_dense_17_accuracy: 0.7555 - val_loss: 0.8792 - val_masked_dense_16_loss: 0.0383 - val_masked_dense_17_loss: 0.8409 - val_masked_dense_16_accuracy: 0.9920 - val_masked_dense_17_accuracy: 0.7240\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7821 - masked_dense_16_loss: 0.0400 - masked_dense_17_loss: 0.7422 - masked_dense_16_accuracy: 0.9914 - masked_dense_17_accuracy: 0.7573 - val_loss: 0.8505 - val_masked_dense_16_loss: 0.0404 - val_masked_dense_17_loss: 0.8100 - val_masked_dense_16_accuracy: 0.9900 - val_masked_dense_17_accuracy: 0.7355\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7691 - masked_dense_16_loss: 0.0401 - masked_dense_17_loss: 0.7289 - masked_dense_16_accuracy: 0.9908 - masked_dense_17_accuracy: 0.7624 - val_loss: 0.8600 - val_masked_dense_16_loss: 0.0381 - val_masked_dense_17_loss: 0.8219 - val_masked_dense_16_accuracy: 0.9915 - val_masked_dense_17_accuracy: 0.7320\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7621 - masked_dense_16_loss: 0.0402 - masked_dense_17_loss: 0.7219 - masked_dense_16_accuracy: 0.9914 - masked_dense_17_accuracy: 0.7616 - val_loss: 0.8636 - val_masked_dense_16_loss: 0.0398 - val_masked_dense_17_loss: 0.8238 - val_masked_dense_16_accuracy: 0.9900 - val_masked_dense_17_accuracy: 0.7390\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7565 - masked_dense_16_loss: 0.0392 - masked_dense_17_loss: 0.7173 - masked_dense_16_accuracy: 0.9919 - masked_dense_17_accuracy: 0.7641 - val_loss: 0.8391 - val_masked_dense_16_loss: 0.0386 - val_masked_dense_17_loss: 0.8005 - val_masked_dense_16_accuracy: 0.9895 - val_masked_dense_17_accuracy: 0.7395\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7458 - masked_dense_16_loss: 0.0401 - masked_dense_17_loss: 0.7057 - masked_dense_16_accuracy: 0.9914 - masked_dense_17_accuracy: 0.7709 - val_loss: 0.8412 - val_masked_dense_16_loss: 0.0407 - val_masked_dense_17_loss: 0.8004 - val_masked_dense_16_accuracy: 0.9905 - val_masked_dense_17_accuracy: 0.7465\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7406 - masked_dense_16_loss: 0.0388 - masked_dense_17_loss: 0.7018 - masked_dense_16_accuracy: 0.9913 - masked_dense_17_accuracy: 0.7713 - val_loss: 0.8164 - val_masked_dense_16_loss: 0.0451 - val_masked_dense_17_loss: 0.7713 - val_masked_dense_16_accuracy: 0.9885 - val_masked_dense_17_accuracy: 0.7475\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7266 - masked_dense_16_loss: 0.0398 - masked_dense_17_loss: 0.6868 - masked_dense_16_accuracy: 0.9915 - masked_dense_17_accuracy: 0.7778 - val_loss: 0.8133 - val_masked_dense_16_loss: 0.0399 - val_masked_dense_17_loss: 0.7734 - val_masked_dense_16_accuracy: 0.9900 - val_masked_dense_17_accuracy: 0.7545\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 15ms/step - loss: 0.7206 - masked_dense_16_loss: 0.0404 - masked_dense_17_loss: 0.6803 - masked_dense_16_accuracy: 0.9910 - masked_dense_17_accuracy: 0.7803 - val_loss: 0.8066 - val_masked_dense_16_loss: 0.0401 - val_masked_dense_17_loss: 0.7664 - val_masked_dense_16_accuracy: 0.9875 - val_masked_dense_17_accuracy: 0.7500\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 16ms/step - loss: 0.7086 - masked_dense_16_loss: 0.0380 - masked_dense_17_loss: 0.6706 - masked_dense_16_accuracy: 0.9920 - masked_dense_17_accuracy: 0.7813 - val_loss: 0.8170 - val_masked_dense_16_loss: 0.0381 - val_masked_dense_17_loss: 0.7790 - val_masked_dense_16_accuracy: 0.9905 - val_masked_dense_17_accuracy: 0.7500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 08:30:59.567906: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "# Train a Multitask Model\n",
    "\n",
    "input1 = tf.keras.layers.Input(x1.shape[-1])\n",
    "input2 = tf.keras.layers.Input(x2.shape[-1])\n",
    "dense1 = mann.layers.MaskedDense(100, activation = 'relu')(input1)\n",
    "dense2 = mann.layers.MaskedDense(100, activation = 'relu')(input2)\n",
    "x = mann.layers.MultiMaskedDense(100, activation = 'relu')([dense1, dense2])\n",
    "for _ in range(4):\n",
    "    x = mann.layers.MultiMaskedDense(100, activation = 'relu')(x)\n",
    "sel1 = mann.layers.SelectorLayer(0)(x)\n",
    "sel2 = mann.layers.SelectorLayer(1)(x)\n",
    "output1 = mann.layers.MaskedDense(1, activation = 'sigmoid')(sel1)\n",
    "output2 = mann.layers.MaskedDense(10, activation = 'sigmoid')(sel2)\n",
    "\n",
    "model =  tf.keras.Model([input1, input2], [output1, output2])\n",
    "model.compile(\n",
    "    loss = ['binary_crossentropy', 'sparse_categorical_crossentropy'],\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "model = mann.utils.mask_model(\n",
    "    model,\n",
    "    90,\n",
    "    method = 'gradients',\n",
    "    exclusive = True,\n",
    "    x = [x1[:2000], x2[:2000]],\n",
    "    y = [y1.reshape(-1, 1)[:2000], y2.reshape(-1, 1)[:2000]]\n",
    ")\n",
    "model.compile(\n",
    "    loss = ['binary_crossentropy', 'sparse_categorical_crossentropy'],\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "model.fit([x1, x2], [y1, y2], epochs = 100, batch_size = 128, callbacks = [callback], validation_split = 0.2)\n",
    "p1, p2 = model.predict([x1, x2])\n",
    "p1 = (p1 >= 0.5).astype(int)\n",
    "p2 = p2.argmax(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Using the MANN\n",
    "\n",
    "Now that the MANN model has been trained, we can use it to get predictions just as we would a traditional model. In this case, a list of predictions are returned, with each index corresponding to the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multitask Task 1 Accuracy: 0.9884\n",
      "Multitask Task 2 Accuracy: 0.7721\n"
     ]
    }
   ],
   "source": [
    "print(f'Multitask Task 1 Accuracy: {(p1.flatten() == y1.flatten()).sum()/y1.flatten().shape[0]}')\n",
    "print(f'Multitask Task 2 Accuracy: {(p2.flatten() == y2.flatten()).sum()/y2.flatten().shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07fd4dfe16dca8199191b78ca0db94b53b8075d28d5da1c5fc8a03bfb8b3b4d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
