{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ed32f42-0862-400d-bb48-a02076de88a9",
   "metadata": {},
   "source": [
    "# Using the MANN Package to train a Computer Vision and Fully Connected Multitask Neural Network\n",
    "\n",
    "In this notebook, the MANN package will be used to train a multitask network for three tasks, two of which will be computer vision tasks utilizing a convolutional architecture fed into a few fully-connected layers and one of which will be a tabular task using only a fully-connected architecture.  The convolutional tasks will be trained on both the MNIST Digit and MNIST Fashion datasets, and the third will be the Boston Housing Price dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b14bdb8-e9a9-4311-bfac-435d3069bfc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MinMaxScaler from Scikit Learn, TensorFlow, numpy, and MANN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9b1091-dcec-4ad8-a23f-6cb249e34806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both the MNIST tasks\n",
    "(digit_x_train, digit_y_train), (digit_x_test, digit_y_test) = tf.keras.datasets.mnist.load_data()\n",
    "(fashion_x_train, fashion_y_train), (fashion_x_test, fashion_y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Reshape the images so they have channels and divide by 255 so all values are in [0, 1]\n",
    "digit_x_train = digit_x_train.reshape(digit_x_train.shape + (1,))/255\n",
    "digit_x_test = digit_x_test.reshape(digit_x_test.shape + (1,))/255\n",
    "fashion_x_train = fashion_x_train.reshape(fashion_x_train.shape + (1,))/255\n",
    "fashion_x_test = fashion_x_test.reshape(fashion_x_test.shape + (1,))/255\n",
    "\n",
    "# Load the Boston housing data and reshape the targets so they have one column\n",
    "(boston_x_train, boston_y_train), (boston_x_test, boston_y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "boston_y_train = boston_y_train.reshape(-1, 1)\n",
    "boston_y_test = boston_y_test.reshape(-1, 1)\n",
    "\n",
    "# Scale the Boston housing data to values between 0 and 1, as measured by the training data\n",
    "boston_x_scaler = MinMaxScaler()\n",
    "boston_x_train = boston_x_scaler.fit_transform(boston_x_train)\n",
    "boston_x_test = boston_x_scaler.transform(boston_x_test)\n",
    "\n",
    "# Scale the target values within the Boston housing dataset as well\n",
    "boston_y_scaler = MinMaxScaler()\n",
    "boston_y_train = boston_y_scaler.fit_transform(boston_y_train)\n",
    "boston_y_test = boston_y_scaler.transform(boston_y_test)\n",
    "\n",
    "# Reshape the y data to have one column\n",
    "digit_y_train = digit_y_train.reshape(-1, 1)\n",
    "digit_y_test = digit_y_test.reshape(-1, 1)\n",
    "fashion_y_train = fashion_y_train.reshape(-1, 1)\n",
    "fashion_y_test = fashion_y_test.reshape(-1, 1)\n",
    "boston_y_train = boston_y_train.reshape(-1, 1)\n",
    "boston_y_test = boston_y_test.reshape(-1, 1)\n",
    "\n",
    "# Create a callback to stop training early\n",
    "callback = tf.keras.callbacks.EarlyStopping(min_delta = 0.01, patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c281e90-7485-4a82-bf44-f0a48c95f743",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c81d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input layers\n",
    "digit_input = tf.keras.layers.Input(digit_x_train.shape[1:])\n",
    "fashion_input = tf.keras.layers.Input(fashion_x_train.shape[1:])\n",
    "boston_input = tf.keras.layers.Input(boston_x_train.shape[1:])\n",
    "\n",
    "# Create the convolutional blocks for the image data\n",
    "image_x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")([digit_input, fashion_input])\n",
    "image_x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(image_x)\n",
    "image_x = mann.layers.MultiMaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(image_x)\n",
    "image_x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")([digit_input, fashion_input])\n",
    "image_x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(image_x)\n",
    "image_x = mann.layers.MultiMaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(image_x)\n",
    "digit_selector = mann.layers.SelectorLayer(0)(image_x)\n",
    "fashion_selector = mann.layers.SelectorLayer(1)(image_x)\n",
    "digit_flatten = tf.keras.layers.Flatten()(digit_selector)\n",
    "fashion_flatten = tf.keras.layers.Flatten()(fashion_selector)\n",
    "image_x = mann.layers.MultiMaskedDense(256, activation = 'relu')([digit_flatten, fashion_flatten])\n",
    "\n",
    "digit_x = mann.layers.SelectorLayer(0)(image_x)\n",
    "fashion_x = mann.layers.SelectorLayer(1)(image_x)\n",
    "boston_x = mann.layers.MaskedDense(256, activation = 'relu')(boston_input)\n",
    "boston_x = mann.layers.MaskedDense(256, activation = 'relu')(boston_x)\n",
    "boston_x = mann.layers.MaskedDense(256, activation = 'relu')(boston_x)\n",
    "\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')([digit_x, fashion_x, boston_x])\n",
    "\n",
    "digit_selector = mann.layers.SelectorLayer(0)(x)\n",
    "fashion_selector = mann.layers.SelectorLayer(1)(x)\n",
    "boston_selector = mann.layers.SelectorLayer(2)(x)\n",
    "\n",
    "digit_output = mann.layers.MaskedDense(10, activation = 'softmax')(digit_selector)\n",
    "fashion_output = mann.layers.MaskedDense(10, activation = 'softmax')(fashion_selector)\n",
    "boston_output = mann.layers.MaskedDense(1, activation = 'relu')(boston_selector)\n",
    "\n",
    "model = tf.keras.models.Model([digit_input, fashion_input, boston_input], [digit_output, fashion_output, boston_output])\n",
    "model.compile(\n",
    "    loss = ['sparse_categorical_crossentropy', 'sparse_categorical_crossentropy', 'mae'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf68704",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mann.utils.mask_model(\n",
    "    model,\n",
    "    80,\n",
    "    method = 'gradients',\n",
    "    exclusive = True,\n",
    "    x = [digit_x_train[:boston_x_train.shape[0], :], fashion_x_train[:boston_x_train.shape[0], :], boston_x_train],\n",
    "    y = [digit_y_train[:boston_x_train.shape[0], :], fashion_y_train[:boston_x_train.shape[0], :], boston_y_train]\n",
    ")\n",
    "\n",
    "# Prepare the model for training the first two tasks only\n",
    "model.compile(\n",
    "    loss = ['sparse_categorical_crossentropy', 'sparse_categorical_crossentropy', 'mae'],\n",
    "    optimizer = 'adam',\n",
    "    loss_weights = [1, 1, 0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1653c6-a458-4fe0-8776-51849db815ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the first two tasks\n",
    "model.fit(\n",
    "    [digit_x_train, fashion_x_train, np.zeros((digit_x_train.shape[0], boston_x_train.shape[1]))],\n",
    "    [digit_y_train, fashion_y_train, np.zeros(digit_y_train.shape[0])],\n",
    "    epochs = 100,\n",
    "    batch_size = 128,\n",
    "    callbacks = [callback],\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b45328-6c1e-4b1d-a43e-203279bd9cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the model for training the third task\n",
    "model.compile(\n",
    "    loss = ['sparse_categorical_crossentropy', 'sparse_categorical_crossentropy', 'mae'],\n",
    "    optimizer = 'adam',\n",
    "    loss_weights = [0, 0, 1]\n",
    ")\n",
    "callback = tf.keras.callbacks.EarlyStopping(min_delta = 0.005, patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14956d4a-6785-4f5d-b7be-ae06ef923419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the third task\n",
    "model.fit(\n",
    "    [digit_x_train[:boston_x_train.shape[0]], fashion_x_train[:boston_x_train.shape[0]], boston_x_train],\n",
    "    [digit_y_train[:boston_x_train.shape[0]], fashion_y_train[:boston_x_train.shape[0]], boston_y_train],\n",
    "    epochs = 100,\n",
    "    batch_size = 32,\n",
    "    callbacks = [callback],\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f99504-b547-4fd5-b756-27d52847e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions for all tasks and report the performance\n",
    "digit_preds, fashion_preds, dummy = model.predict([digit_x_test, fashion_x_test, np.zeros((digit_x_test.shape[0], boston_x_test.shape[1]))])\n",
    "dummy1, dummy2, boston_preds = model.predict([digit_x_test[:boston_x_test.shape[0]], fashion_x_test[:boston_x_test.shape[0]], boston_x_test])\n",
    "digit_preds = digit_preds.argmax(axis = 1)\n",
    "fashion_preds = fashion_preds.argmax(axis = 1)\n",
    "\n",
    "print(f'Multitask Digit Accuracy: {(digit_preds.flatten() == digit_y_test.flatten()).sum()/digit_y_test.flatten().shape[0]}')\n",
    "print(f'Multitask Fashion Accuracy: {(fashion_preds.flatten() == fashion_y_test.flatten()).sum()/fashion_y_test.flatten().shape[0]}')\n",
    "print(f'Multitask Boston MAE: {np.abs(boston_preds.flatten() - boston_y_test.flatten()).mean()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
