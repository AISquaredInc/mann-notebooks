{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the MANN Package to train a Convolutional Neural Network\n",
    "\n",
    "In this notebook, the MANN package will be used to train pruned convolutional neural networks.  We will train two single-task networks on two separate tasks and one multitask network which performs both tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MANN package and TensorFlow\n",
    "import tensorflow as tf\n",
    "import mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load both MNIST tasks\n",
    "(digit_x_train, digit_y_train), (digit_x_test, digit_y_test) = tf.keras.datasets.mnist.load_data()\n",
    "(fashion_x_train, fashion_y_train), (fashion_x_test, fashion_y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "# Reshape the x data so they have channels, divide by 255 to place all pixel values in [0, 1]\n",
    "digit_x_train = digit_x_train.reshape(digit_x_train.shape + (1,))/255\n",
    "digit_x_test = digit_x_test.reshape(digit_x_test.shape + (1,))/255\n",
    "fashion_x_train = fashion_x_train.reshape(fashion_x_train.shape + (1,))/255\n",
    "fashion_x_test = fashion_x_test.reshape(fashion_x_test.shape + (1,))/255\n",
    "\n",
    "# Reshape the y data to have 1 column\n",
    "digit_y_train = digit_y_train.reshape(-1, 1)\n",
    "digit_y_test = digit_y_test.reshape(-1, 1)\n",
    "fashion_y_train = fashion_y_train.reshape(-1, 1)\n",
    "fashion_y_test = fashion_y_test.reshape(-1, 1)\n",
    "\n",
    "# Create a callback for early stopping\n",
    "callback = tf.keras.callbacks.EarlyStopping(min_delta = 0.01, patience = 3, restore_best_weights = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the first model\n",
    "\n",
    "This first model is a convolutional model which will perform MNIST digit recognition. It will be pruned utilizing the MANN package so that most of its weights are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:25:38.653338: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-09 07:25:38.654033: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "# Create the input layer for the digit task\n",
    "input_layer = tf.keras.layers.Input(digit_x_train.shape[1:])\n",
    "\n",
    "# Create the convolutional blocks\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(input_layer)\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(x)\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = mann.layers.MaskedDense(256, activation = 'relu')(x)\n",
    "x = mann.layers.MaskedDense(256, activation = 'relu')(x)\n",
    "output_layer = mann.layers.MaskedDense(10, activation = 'softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model for training and to prepare for masking\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Mask (prune) the model using the MANN package\n",
    "model = mann.utils.mask_model(\n",
    "    model = model,              # The model to be pruned\n",
    "    percentile = 80,            # The percentile to be masked, for example, if the value is 90, then 90% of weights will be masked\n",
    "    method = 'gradients',       # The method to use to mask, either 'gradients' or 'magnitude'\n",
    "    exclusive = True,           # Whether weight locations must be exclusive to each task\n",
    "    x = digit_x_train[:1000],   # The input data (using a subset to calculate gradients)\n",
    "    y = digit_y_train[:1000]    # The expected outputs (using a subset to calculate gradients)\n",
    ")\n",
    "\n",
    "# Recompile the model\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.        ,  0.        , -0.        , -0.        ,\n",
       "           0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -0.        ,  0.        , -0.        ,  0.02906718,\n",
       "           0.05429413,  0.        ,  0.        , -0.        ,\n",
       "          -0.02267656, -0.        ,  0.        , -0.        ,\n",
       "          -0.05906082, -0.12245995,  0.04115575,  0.        ,\n",
       "           0.04951426,  0.        ,  0.        ,  0.        ,\n",
       "          -0.        , -0.        , -0.        ,  0.        ]],\n",
       "\n",
       "        [[-0.        ,  0.        , -0.        , -0.        ,\n",
       "           0.        , -0.        ,  0.        ,  0.        ,\n",
       "           0.        , -0.        ,  0.        ,  0.0459222 ,\n",
       "           0.03733057, -0.        ,  0.05112445, -0.        ,\n",
       "           0.05061556, -0.        , -0.        , -0.        ,\n",
       "           0.1067455 ,  0.        , -0.00599049,  0.        ,\n",
       "           0.02466581, -0.        , -0.0068549 ,  0.        ,\n",
       "          -0.        , -0.        , -0.        ,  0.        ]],\n",
       "\n",
       "        [[-0.        , -0.        ,  0.        , -0.        ,\n",
       "          -0.        ,  0.06631131,  0.        ,  0.        ,\n",
       "           0.        ,  0.        ,  0.        , -0.06154874,\n",
       "          -0.        , -0.        ,  0.03363601, -0.        ,\n",
       "           0.        ,  0.        ,  0.        , -0.        ,\n",
       "          -0.03764411, -0.        ,  0.02916553, -0.        ,\n",
       "           0.0661728 ,  0.        , -0.        , -0.        ,\n",
       "           0.02097872, -0.        , -0.        , -0.00067259]]],\n",
       "\n",
       "\n",
       "       [[[-0.        ,  0.        ,  0.        , -0.        ,\n",
       "           0.        ,  0.        , -0.        ,  0.        ,\n",
       "          -0.        , -0.        , -0.        , -0.04796097,\n",
       "           0.        , -0.        , -0.0011878 ,  0.        ,\n",
       "           0.        , -0.        ,  0.        ,  0.        ,\n",
       "           0.04450726,  0.        ,  0.03493053, -0.        ,\n",
       "           0.06522722, -0.        , -0.        , -0.        ,\n",
       "          -0.        ,  0.        ,  0.        ,  0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          -0.        , -0.        , -0.        ,  0.        ,\n",
       "          -0.        , -0.        ,  0.        ,  0.11286216,\n",
       "          -0.        , -0.        ,  0.0229982 ,  0.        ,\n",
       "          -0.        , -0.        ,  0.        , -0.        ,\n",
       "           0.0262911 ,  0.        , -0.00983763,  0.        ,\n",
       "          -0.02218382, -0.        , -0.        , -0.        ,\n",
       "           0.        ,  0.        , -0.        , -0.12557936]],\n",
       "\n",
       "        [[ 0.        ,  0.        , -0.        , -0.        ,\n",
       "          -0.        ,  0.06494873, -0.        , -0.        ,\n",
       "          -0.        , -0.        , -0.        ,  0.04880148,\n",
       "          -0.        ,  0.        ,  0.05548797, -0.        ,\n",
       "           0.        ,  0.        , -0.        , -0.        ,\n",
       "           0.08537171,  0.        , -0.02403991, -0.        ,\n",
       "          -0.05236127, -0.        ,  0.        ,  0.        ,\n",
       "          -0.02205553, -0.        ,  0.        ,  0.02603555]]],\n",
       "\n",
       "\n",
       "       [[[-0.        ,  0.        , -0.        ,  0.        ,\n",
       "          -0.        ,  0.        , -0.        ,  0.        ,\n",
       "           0.        , -0.        , -0.        ,  0.02110312,\n",
       "           0.        , -0.        , -0.        , -0.        ,\n",
       "           0.        , -0.        ,  0.        , -0.        ,\n",
       "          -0.0509158 ,  0.        , -0.0282634 , -0.        ,\n",
       "           0.        , -0.        ,  0.        , -0.        ,\n",
       "          -0.        , -0.        ,  0.        , -0.        ]],\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        , -0.        ,\n",
       "          -0.        , -0.0211696 , -0.        , -0.        ,\n",
       "           0.        , -0.        ,  0.        , -0.02939454,\n",
       "           0.        ,  0.        ,  0.01009036,  0.        ,\n",
       "           0.        , -0.        ,  0.        ,  0.        ,\n",
       "          -0.        ,  0.0288609 ,  0.00519633, -0.        ,\n",
       "           0.        , -0.        ,  0.        , -0.        ,\n",
       "           0.        ,  0.        , -0.        ,  0.02014625]],\n",
       "\n",
       "        [[-0.        , -0.        , -0.        , -0.        ,\n",
       "           0.        ,  0.00313363, -0.        , -0.        ,\n",
       "           0.        ,  0.        , -0.        , -0.00865172,\n",
       "           0.        , -0.        ,  0.03571336, -0.        ,\n",
       "           0.        ,  0.        , -0.        ,  0.        ,\n",
       "          -0.        ,  0.00668773,  0.05411475, -0.        ,\n",
       "          -0.        , -0.        ,  0.        , -0.        ,\n",
       "           0.01480117, -0.        ,  0.        ,  0.06368148]]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the sparsity of the model\n",
    "model.layers[1].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:26:22.954960: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-09 07:26:22.957940: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:26:23.170031: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - ETA: 0s - loss: 0.3538 - accuracy: 0.8902"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:26:56.007482: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 36s 94ms/step - loss: 0.3538 - accuracy: 0.8902 - val_loss: 0.1025 - val_accuracy: 0.9703\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 35s 93ms/step - loss: 0.0813 - accuracy: 0.9756 - val_loss: 0.0761 - val_accuracy: 0.9790\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 35s 94ms/step - loss: 0.0540 - accuracy: 0.9834 - val_loss: 0.0548 - val_accuracy: 0.9831\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 35s 92ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.0716 - val_accuracy: 0.9818\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 35s 93ms/step - loss: 0.0293 - accuracy: 0.9907 - val_loss: 0.0544 - val_accuracy: 0.9853\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 35s 94ms/step - loss: 0.0232 - accuracy: 0.9924 - val_loss: 0.0463 - val_accuracy: 0.9878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:29:54.027378: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Digit Model Accuracy: 0.9864\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the first dataset\n",
    "model.fit(\n",
    "    digit_x_train,\n",
    "    digit_y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 100,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [callback]\n",
    ")\n",
    "print(f'Digit Model Accuracy: {(model.predict(digit_x_test).argmax(axis = 1).flatten() == digit_y_test.flatten()).sum()/digit_y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the second model\n",
    "\n",
    "The second model will have an identical architecture to the first, but it will be trained to perform MNIST fashion recognition instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the input layer for the fashion task\n",
    "input_layer = tf.keras.layers.Input(fashion_x_train.shape[1:])\n",
    "\n",
    "# Create the convolutional blocks\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(input_layer)\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(x)\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = mann.layers.MaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = tf.keras.layers.MaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(x)\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = mann.layers.MaskedDense(256, activation = 'relu')(x)\n",
    "x = mann.layers.MaskedDense(256, activation = 'relu')(x)\n",
    "output_layer = mann.layers.MaskedDense(10, activation = 'softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model(input_layer, output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model for training and to prepare for masking\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Mask (prune) the model using the MANN package\n",
    "model = mann.utils.mask_model(\n",
    "    model = model,              # The model to be pruned\n",
    "    percentile = 80,            # The percentile to be masked, for example, if the value is 90, then 90% of weights will be masked\n",
    "    method = 'gradients',       # The method to use to mask, either 'gradients' or 'magnitude'\n",
    "    exclusive = True,           # Whether weight locations must be exclusive to each task\n",
    "    x = fashion_x_train[:1000], # The input data (using a subset to calculate gradients)\n",
    "    y = fashion_y_train[:1000]  # The expected outputs (using a subset to calculate gradients)\n",
    ")\n",
    "\n",
    "# Recompile the model\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:30:04.183111: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.7523"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:30:35.875719: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 35s 93ms/step - loss: 0.6690 - accuracy: 0.7523 - val_loss: 0.4472 - val_accuracy: 0.8403\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 35s 92ms/step - loss: 0.3974 - accuracy: 0.8595 - val_loss: 0.3747 - val_accuracy: 0.8682\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 34s 92ms/step - loss: 0.3344 - accuracy: 0.8789 - val_loss: 0.3323 - val_accuracy: 0.8767\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 34s 92ms/step - loss: 0.2872 - accuracy: 0.8957 - val_loss: 0.2913 - val_accuracy: 0.8937\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 35s 92ms/step - loss: 0.2547 - accuracy: 0.9072 - val_loss: 0.2776 - val_accuracy: 0.8961\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 35s 92ms/step - loss: 0.2267 - accuracy: 0.9159 - val_loss: 0.2530 - val_accuracy: 0.9066\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 34s 92ms/step - loss: 0.1986 - accuracy: 0.9268 - val_loss: 0.2530 - val_accuracy: 0.9105\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 34s 92ms/step - loss: 0.1784 - accuracy: 0.9352 - val_loss: 0.2580 - val_accuracy: 0.9124\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 34s 92ms/step - loss: 0.1562 - accuracy: 0.9432 - val_loss: 0.2577 - val_accuracy: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:35:15.092436: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion Model Accuracy: 0.8995\n"
     ]
    }
   ],
   "source": [
    "# Fit the model on the second dataset\n",
    "model.fit(\n",
    "    fashion_x_train,\n",
    "    fashion_y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 100,\n",
    "    validation_split = 0.2,\n",
    "    callbacks = [callback]\n",
    ")\n",
    "print(f'Fashion Model Accuracy: {(model.predict(fashion_x_test).argmax(axis = 1).flatten() == fashion_y_test.flatten()).sum()/fashion_y_test.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the MANN\n",
    "\n",
    "The third and final model we create here will be a multitask model (MANN) which performs both the MNIST digit recognition and the MNIST fashion recognition tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Multitask Model\n",
    "digit_input = tf.keras.layers.Input(digit_x_train.shape[1:])\n",
    "fashion_input = tf.keras.layers.Input(fashion_x_train.shape[1:])\n",
    "\n",
    "# Create the convolutional blocks\n",
    "x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")([digit_input, fashion_input])\n",
    "x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 32,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = mann.layers.MultiMaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(x)\n",
    "x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = mann.layers.MultiMaskedConv2D(\n",
    "    filters = 64,\n",
    "    kernel_size = 3,\n",
    "    padding = 'same',\n",
    "    strides = 1,\n",
    "    activation = 'relu'\n",
    ")(x)\n",
    "x = mann.layers.MultiMaxPool2D(\n",
    "    pool_size = 2,\n",
    "    strides = 1,\n",
    "    padding = 'valid'\n",
    ")(x)\n",
    "\n",
    "# SelectorLayer for the first task\n",
    "sel1 = mann.layers.SelectorLayer(0)(x)\n",
    "digit_flatten = tf.keras.layers.Flatten()(sel1)\n",
    "\n",
    "# SelectorLayer for the second task\n",
    "sel2 = mann.layers.SelectorLayer(1)(x)\n",
    "fashion_flatten = tf.keras.layers.Flatten()(sel2)\n",
    "\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')([digit_flatten, fashion_flatten])\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')(x)\n",
    "output_layer = mann.layers.MultiMaskedDense(10, activation = 'softmax')(x)\n",
    "\n",
    "# Create the model\n",
    "model = tf.keras.Model([digit_input, fashion_input], output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:35:24.650070: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - ETA: 0s - loss: 1.0392 - multi_masked_dense_2_loss: 0.3406 - multi_masked_dense_2_1_loss: 0.6986 - multi_masked_dense_2_accuracy: 0.8944 - multi_masked_dense_2_1_accuracy: 0.7496"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:36:33.194804: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 76s 201ms/step - loss: 1.0392 - multi_masked_dense_2_loss: 0.3406 - multi_masked_dense_2_1_loss: 0.6986 - multi_masked_dense_2_accuracy: 0.8944 - multi_masked_dense_2_1_accuracy: 0.7496 - val_loss: 0.5564 - val_multi_masked_dense_2_loss: 0.1030 - val_multi_masked_dense_2_1_loss: 0.4534 - val_multi_masked_dense_2_accuracy: 0.9681 - val_multi_masked_dense_2_1_accuracy: 0.8379\n",
      "Epoch 2/100\n",
      "375/375 [==============================] - 75s 200ms/step - loss: 0.4368 - multi_masked_dense_2_loss: 0.0758 - multi_masked_dense_2_1_loss: 0.3610 - multi_masked_dense_2_accuracy: 0.9768 - multi_masked_dense_2_1_accuracy: 0.8707 - val_loss: 0.3866 - val_multi_masked_dense_2_loss: 0.0650 - val_multi_masked_dense_2_1_loss: 0.3216 - val_multi_masked_dense_2_accuracy: 0.9797 - val_multi_masked_dense_2_1_accuracy: 0.8838\n",
      "Epoch 3/100\n",
      "375/375 [==============================] - 75s 199ms/step - loss: 0.3297 - multi_masked_dense_2_loss: 0.0484 - multi_masked_dense_2_1_loss: 0.2812 - multi_masked_dense_2_accuracy: 0.9843 - multi_masked_dense_2_1_accuracy: 0.8975 - val_loss: 0.3348 - val_multi_masked_dense_2_loss: 0.0499 - val_multi_masked_dense_2_1_loss: 0.2849 - val_multi_masked_dense_2_accuracy: 0.9849 - val_multi_masked_dense_2_1_accuracy: 0.8975\n",
      "Epoch 4/100\n",
      "375/375 [==============================] - 75s 199ms/step - loss: 0.2638 - multi_masked_dense_2_loss: 0.0352 - multi_masked_dense_2_1_loss: 0.2286 - multi_masked_dense_2_accuracy: 0.9891 - multi_masked_dense_2_1_accuracy: 0.9149 - val_loss: 0.3010 - val_multi_masked_dense_2_loss: 0.0523 - val_multi_masked_dense_2_1_loss: 0.2487 - val_multi_masked_dense_2_accuracy: 0.9862 - val_multi_masked_dense_2_1_accuracy: 0.9103\n",
      "Epoch 5/100\n",
      "375/375 [==============================] - 75s 199ms/step - loss: 0.2185 - multi_masked_dense_2_loss: 0.0242 - multi_masked_dense_2_1_loss: 0.1943 - multi_masked_dense_2_accuracy: 0.9923 - multi_masked_dense_2_1_accuracy: 0.9290 - val_loss: 0.3005 - val_multi_masked_dense_2_loss: 0.0556 - val_multi_masked_dense_2_1_loss: 0.2450 - val_multi_masked_dense_2_accuracy: 0.9859 - val_multi_masked_dense_2_1_accuracy: 0.9176\n",
      "Epoch 6/100\n",
      "375/375 [==============================] - 75s 199ms/step - loss: 0.1789 - multi_masked_dense_2_loss: 0.0196 - multi_masked_dense_2_1_loss: 0.1593 - multi_masked_dense_2_accuracy: 0.9935 - multi_masked_dense_2_1_accuracy: 0.9412 - val_loss: 0.2805 - val_multi_masked_dense_2_loss: 0.0509 - val_multi_masked_dense_2_1_loss: 0.2296 - val_multi_masked_dense_2_accuracy: 0.9872 - val_multi_masked_dense_2_1_accuracy: 0.9218\n",
      "Epoch 7/100\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.1474 - multi_masked_dense_2_loss: 0.0168 - multi_masked_dense_2_1_loss: 0.1306 - multi_masked_dense_2_accuracy: 0.9948 - multi_masked_dense_2_1_accuracy: 0.9517 - val_loss: 0.3068 - val_multi_masked_dense_2_loss: 0.0541 - val_multi_masked_dense_2_1_loss: 0.2527 - val_multi_masked_dense_2_accuracy: 0.9857 - val_multi_masked_dense_2_1_accuracy: 0.9168\n",
      "Epoch 8/100\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.1162 - multi_masked_dense_2_loss: 0.0117 - multi_masked_dense_2_1_loss: 0.1045 - multi_masked_dense_2_accuracy: 0.9962 - multi_masked_dense_2_1_accuracy: 0.9615 - val_loss: 0.3233 - val_multi_masked_dense_2_loss: 0.0587 - val_multi_masked_dense_2_1_loss: 0.2646 - val_multi_masked_dense_2_accuracy: 0.9846 - val_multi_masked_dense_2_1_accuracy: 0.9237\n",
      "Epoch 9/100\n",
      "375/375 [==============================] - 75s 201ms/step - loss: 0.0952 - multi_masked_dense_2_loss: 0.0123 - multi_masked_dense_2_1_loss: 0.0829 - multi_masked_dense_2_accuracy: 0.9961 - multi_masked_dense_2_1_accuracy: 0.9696 - val_loss: 0.3330 - val_multi_masked_dense_2_loss: 0.0496 - val_multi_masked_dense_2_1_loss: 0.2834 - val_multi_masked_dense_2_accuracy: 0.9872 - val_multi_masked_dense_2_1_accuracy: 0.9229\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x165cc0940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform masking\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    \n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "model = mann.utils.mask_model(\n",
    "    model,\n",
    "    80,\n",
    "    method = 'gradients',\n",
    "    exclusive = True,\n",
    "    x = [digit_x_train[:1000], fashion_x_train[:1000]],\n",
    "    y = [digit_y_train[:1000], fashion_y_train[:1000]]\n",
    ")\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    [digit_x_train, fashion_x_train],\n",
    "    [digit_y_train, fashion_y_train],\n",
    "    epochs = 100,\n",
    "    batch_size = 128,\n",
    "    callbacks = [callback],\n",
    "    validation_split = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict Using the MANN\n",
    "\n",
    "Now that the MANN model has been trained, we can use it to get predictions just as we would a traditional model. In this case, a list of predictions are returned, with each index corresponding to the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-09 07:46:41.027169: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multitask Model Digit Accuracy: 0.9883\n",
      "Multitask Model Fashion Accuracy: 0.9164\n"
     ]
    }
   ],
   "source": [
    "digit_preds, fashion_preds = model.predict([digit_x_test, fashion_x_test])\n",
    "digit_preds = digit_preds.argmax(axis = 1)\n",
    "fashion_preds = fashion_preds.argmax(axis = 1)\n",
    "\n",
    "print(f'Multitask Model Digit Accuracy: {(digit_preds.flatten() == digit_y_test.flatten()).sum()/digit_y_test.flatten().shape[0]}')\n",
    "print(f'Multitask Model Fashion Accuracy: {(fashion_preds.flatten() == fashion_y_test.flatten()).sum()/fashion_y_test.flatten().shape[0]}')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07fd4dfe16dca8199191b78ca0db94b53b8075d28d5da1c5fc8a03bfb8b3b4d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
