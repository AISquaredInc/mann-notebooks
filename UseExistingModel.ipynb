{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the MANN Package to convert and prune an existing TensorFlow model\n",
    "\n",
    "In this notebook, we utilize the MANN package on an existing TensorFlow model to convert existing layers to MANN layers and then prune the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MANN package and TensorFlow\n",
    "import tensorflow as tf\n",
    "import beyondml.tflow as mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 10:45:34.442895: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-03 10:45:34.442998: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# Load the model to be used\n",
    "vgg16 = tf.keras.applications.VGG16(\n",
    "    include_top = False,             # Don't include the top layers\n",
    "    weights = 'imagenet',            # Load the imagenet weights\n",
    "    input_shape = x_train.shape[1:]  # Input shape is the shape of the images\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model to be trained\n",
    "\n",
    "In the following cell, we create the model using the existing VGG model fed into fully-connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,507,786\n",
      "Trainable params: 15,507,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model using VGG16 and a few layers on top of it\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(vgg16)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Present model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model and perform initial pruning\n",
    "\n",
    "In the following cell, we convert the model and perform initial pruning of the model to 40%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         29429376  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "masked_dense (MaskedDense)   (None, 512)               525312    \n",
      "_________________________________________________________________\n",
      "masked_dense_1 (MaskedDense) (None, 512)               525312    \n",
      "_________________________________________________________________\n",
      "masked_dense_2 (MaskedDense) (None, 512)               525312    \n",
      "_________________________________________________________________\n",
      "masked_dense_3 (MaskedDense) (None, 10)                10260     \n",
      "=================================================================\n",
      "Total params: 31,015,572\n",
      "Trainable params: 15,507,786\n",
      "Non-trainable params: 15,507,786\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use the add_layer_masks function to add masking layers to the model\n",
    "converted_model = mann.utils.add_layer_masks(model)\n",
    "\n",
    "# Compile the model\n",
    "converted_model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Mask the model using magnitude as the metric\n",
    "converted_model = mann.utils.mask_model(\n",
    "    converted_model,\n",
    "    40,\n",
    "    method = 'magnitude'\n",
    ")\n",
    "\n",
    "# Recompile the model for the weights to take effect\n",
    "converted_model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Present the model summary\n",
    "converted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and further prune the model\n",
    "\n",
    "In this cell, we create the ActiveSparsification callback and train the model using that callback to prune the model as the model improves in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 10:45:35.917442: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-03 10:45:35.918470: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 10:45:36.127297: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/157 [>.............................] - ETA: 49s - loss: 2.4471 - accuracy: 0.0944WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0993s vs `on_train_batch_end` time: 0.2171s). Check your callbacks.\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.9748 - accuracy: 0.2022"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 10:46:28.293310: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 56s 354ms/step - loss: 1.9748 - accuracy: 0.2022 - val_loss: 1.7803 - val_accuracy: 0.2515\n",
      "Performance measure set to val_accuracy\n",
      "Model performance has not reached pruning threshold for 1 epoch(s)\n",
      "Epoch 2/1000\n",
      "157/157 [==============================] - 55s 349ms/step - loss: 1.5569 - accuracy: 0.3574 - val_loss: 1.4051 - val_accuracy: 0.4592\n",
      "Model performance has not reached pruning threshold for 2 epoch(s)\n",
      "Epoch 3/1000\n",
      "157/157 [==============================] - 55s 348ms/step - loss: 1.1886 - accuracy: 0.5540 - val_loss: 1.0138 - val_accuracy: 0.6401\n",
      "Model performance has not reached pruning threshold for 3 epoch(s)\n",
      "Epoch 4/1000\n",
      "157/157 [==============================] - 55s 348ms/step - loss: 0.8670 - accuracy: 0.6950 - val_loss: 0.8634 - val_accuracy: 0.6979\n",
      "Model performance has not reached pruning threshold for 4 epoch(s)\n",
      "Epoch 5/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.6957 - accuracy: 0.7677 - val_loss: 0.7053 - val_accuracy: 0.7692\n",
      "Model performance reached 0.77, sparsifying to 45\n",
      "Epoch 6/1000\n",
      "157/157 [==============================] - 55s 353ms/step - loss: 0.5593 - accuracy: 0.8130 - val_loss: 0.6869 - val_accuracy: 0.7875\n",
      "Model performance reached 0.79, sparsifying to 50\n",
      "Epoch 7/1000\n",
      "157/157 [==============================] - 55s 349ms/step - loss: 0.4488 - accuracy: 0.8543 - val_loss: 0.6594 - val_accuracy: 0.7963\n",
      "Model performance reached 0.8, sparsifying to 55\n",
      "Epoch 8/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.3926 - accuracy: 0.8716 - val_loss: 0.6386 - val_accuracy: 0.7992\n",
      "Model performance reached 0.8, sparsifying to 60\n",
      "Epoch 9/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.3177 - accuracy: 0.8974 - val_loss: 0.6563 - val_accuracy: 0.8114\n",
      "Model performance reached 0.81, sparsifying to 65\n",
      "Epoch 10/1000\n",
      "157/157 [==============================] - 55s 349ms/step - loss: 0.2807 - accuracy: 0.9116 - val_loss: 0.7512 - val_accuracy: 0.7969\n",
      "Model performance reached 0.8, sparsifying to 70\n",
      "Epoch 11/1000\n",
      "157/157 [==============================] - 55s 349ms/step - loss: 0.2513 - accuracy: 0.9214 - val_loss: 0.7349 - val_accuracy: 0.7974\n",
      "Model performance reached 0.8, sparsifying to 75\n",
      "Epoch 12/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.2071 - accuracy: 0.9358 - val_loss: 0.7966 - val_accuracy: 0.8060\n",
      "Model performance reached 0.81, sparsifying to 80\n",
      "Epoch 13/1000\n",
      "157/157 [==============================] - 55s 348ms/step - loss: 0.1849 - accuracy: 0.9434 - val_loss: 0.7987 - val_accuracy: 0.8061\n",
      "Model performance reached 0.81, sparsifying to 85\n",
      "Epoch 14/1000\n",
      "157/157 [==============================] - 55s 352ms/step - loss: 0.1623 - accuracy: 0.9499 - val_loss: 0.7436 - val_accuracy: 0.8087\n",
      "Model performance reached 0.81, sparsifying to 90\n",
      "Epoch 15/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.1382 - accuracy: 0.9576 - val_loss: 0.8945 - val_accuracy: 0.8019\n",
      "Model performance reached 0.8, sparsifying to 95\n",
      "Epoch 16/1000\n",
      "157/157 [==============================] - 56s 360ms/step - loss: 0.1340 - accuracy: 0.9601 - val_loss: 0.7836 - val_accuracy: 0.8114\n",
      "Model cannot be sparsified further due to max sparsification parameter\n",
      "Epoch 17/1000\n",
      "157/157 [==============================] - 55s 353ms/step - loss: 0.1192 - accuracy: 0.9638 - val_loss: 0.9609 - val_accuracy: 0.7810\n",
      "Early stopping performance has not met threshold for 1 epochs\n",
      "Epoch 18/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.1572 - accuracy: 0.9530 - val_loss: 0.8514 - val_accuracy: 0.8007\n",
      "Early stopping performance has not met threshold for 2 epochs\n",
      "Epoch 19/1000\n",
      "157/157 [==============================] - 55s 349ms/step - loss: 0.1146 - accuracy: 0.9662 - val_loss: 0.8418 - val_accuracy: 0.8079\n",
      "Early stopping performance has not met threshold for 3 epochs\n",
      "Epoch 20/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.0902 - accuracy: 0.9732 - val_loss: 0.8649 - val_accuracy: 0.8189\n",
      "Early stopping performance has not met threshold for 4 epochs\n",
      "Epoch 21/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.0859 - accuracy: 0.9748 - val_loss: 0.9017 - val_accuracy: 0.8093\n",
      "Early stopping performance has not met threshold for 5 epochs\n",
      "Model performance has not met early stopping criteria. Stopping training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x339e26430>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the sparsification callback object\n",
    "callback = mann.utils.ActiveSparsification(\n",
    "    performance_cutoff = 0.75,    # The accuracy score the model needs to achieve\n",
    "    starting_sparsification = 40, # Starting sparsification\n",
    "    sparsification_rate = 5       # Sparsification increase every time the model achieves performance cutoff\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 1000,\n",
    "    callbacks = [callback],\n",
    "    validation_split = 0.2,\n",
    "    batch_size = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the model back to remove masking layers\n",
    "\n",
    "In the following cell, we remove the layer masks created for training, while completely preserving performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,507,786\n",
      "Trainable params: 0\n",
      "Non-trainable params: 15,507,786\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convert the model back\n",
    "model = mann.utils.remove_layer_masks(model)\n",
    "\n",
    "# Present the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report accuracy and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 11:04:54.104795: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.8001\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions on test data\n",
    "preds = model.predict(x_test).argmax(axis = 1)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Model Accuracy: {(preds.flatten() == y_test.flatten()).sum().astype(int)/y_test.flatten().shape[0]}')\n",
    "\n",
    "# Save the model\n",
    "model.save('cifar_vgg16.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0671325c08d22fc44ce2e58aedbf8efae69ce5eb9c1911bbe321ecb24080d883"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 22 2022, 08:25:29) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
