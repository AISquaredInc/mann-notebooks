{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the MANN Package to convert and prune an existing TensorFlow model\n",
    "\n",
    "In this notebook, we utilize the MANN package on an existing TensorFlow model to convert existing layers to MANN layers and then prune the model using RSN2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MANN package and TensorFlow\n",
    "import tensorflow as tf\n",
    "import mann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 08:01:16.867707: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-03-03 08:01:16.867812: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "# Load the model to be used\n",
    "vgg16 = tf.keras.applications.VGG16(\n",
    "    include_top = False,             # Don't include the top layers\n",
    "    weights = 'imagenet',            # Load the imagenet weights\n",
    "    input_shape = x_train.shape[1:]  # Input shape is the shape of the images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,507,786\n",
      "Trainable params: 15,507,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build the model using VGG16 and a few layers on top of it\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(vgg16)\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(512, activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dense(10, activation = 'softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Present model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         29429376  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "masked_dense (MaskedDense)   (None, 512)               525312    \n",
      "_________________________________________________________________\n",
      "masked_dense_1 (MaskedDense) (None, 512)               525312    \n",
      "_________________________________________________________________\n",
      "masked_dense_2 (MaskedDense) (None, 512)               525312    \n",
      "_________________________________________________________________\n",
      "masked_dense_3 (MaskedDense) (None, 10)                10260     \n",
      "=================================================================\n",
      "Total params: 31,015,572\n",
      "Trainable params: 15,507,786\n",
      "Non-trainable params: 15,507,786\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Use the add_layer_masks function to add masking layers to the model\n",
    "converted_model = mann.utils.add_layer_masks(model)\n",
    "\n",
    "# Compile the model\n",
    "converted_model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Mask the model using magnitude as the metric\n",
    "converted_model = mann.utils.mask_model(\n",
    "    converted_model,\n",
    "    40,\n",
    "    method = 'magnitude'\n",
    ")\n",
    "\n",
    "# Recompile the model for the weights to take effect\n",
    "converted_model.compile(\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy'],\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Present the model summary\n",
    "converted_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 08:01:18.327110: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-03-03 08:01:18.327285: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 08:01:18.529887: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/157 [>.............................] - ETA: 48s - loss: 2.3692 - accuracy: 0.0996WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0978s vs `on_train_batch_end` time: 0.2148s). Check your callbacks.\n",
      "157/157 [==============================] - ETA: 0s - loss: 1.9852 - accuracy: 0.2017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-03 08:02:10.787439: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 56s 354ms/step - loss: 1.9852 - accuracy: 0.2017 - val_loss: 1.7798 - val_accuracy: 0.2741\n",
      "Performance measure set to val_accuracy\n",
      "Model performance has not reached pruning threshold for 1 epoch(s)\n",
      "Epoch 2/1000\n",
      "157/157 [==============================] - 54s 346ms/step - loss: 1.7332 - accuracy: 0.2871 - val_loss: 1.8261 - val_accuracy: 0.2843\n",
      "Model performance has not reached pruning threshold for 2 epoch(s)\n",
      "Epoch 3/1000\n",
      "157/157 [==============================] - 54s 345ms/step - loss: 1.4679 - accuracy: 0.4106 - val_loss: 1.4511 - val_accuracy: 0.4686\n",
      "Model performance has not reached pruning threshold for 3 epoch(s)\n",
      "Epoch 4/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 1.1497 - accuracy: 0.5736 - val_loss: 0.9907 - val_accuracy: 0.6472\n",
      "Model performance has not reached pruning threshold for 4 epoch(s)\n",
      "Epoch 5/1000\n",
      "157/157 [==============================] - 55s 350ms/step - loss: 0.8669 - accuracy: 0.6986 - val_loss: 0.8482 - val_accuracy: 0.7092\n",
      "Model performance has not reached pruning threshold for 5 epoch(s)\n",
      "Epoch 6/1000\n",
      "157/157 [==============================] - 55s 347ms/step - loss: 0.6906 - accuracy: 0.7656 - val_loss: 0.7413 - val_accuracy: 0.7540\n",
      "Model performance reached 0.75, sparsifying to 45\n",
      "Epoch 7/1000\n",
      "157/157 [==============================] - 54s 346ms/step - loss: 0.5754 - accuracy: 0.8061 - val_loss: 0.7293 - val_accuracy: 0.7607\n",
      "Model performance reached 0.76, sparsifying to 50\n",
      "Epoch 8/1000\n",
      "157/157 [==============================] - 55s 353ms/step - loss: 0.4683 - accuracy: 0.8429 - val_loss: 0.7536 - val_accuracy: 0.7714\n",
      "Model performance reached 0.77, sparsifying to 55\n",
      "Epoch 9/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.4016 - accuracy: 0.8687 - val_loss: 0.7127 - val_accuracy: 0.7868\n",
      "Model performance reached 0.79, sparsifying to 60\n",
      "Epoch 10/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.3283 - accuracy: 0.8929 - val_loss: 0.7053 - val_accuracy: 0.7910\n",
      "Model performance reached 0.79, sparsifying to 65\n",
      "Epoch 11/1000\n",
      "157/157 [==============================] - 54s 345ms/step - loss: 0.2768 - accuracy: 0.9105 - val_loss: 0.7038 - val_accuracy: 0.7908\n",
      "Model performance reached 0.79, sparsifying to 70\n",
      "Epoch 12/1000\n",
      "157/157 [==============================] - 54s 345ms/step - loss: 0.2451 - accuracy: 0.9213 - val_loss: 0.7397 - val_accuracy: 0.8012\n",
      "Model performance reached 0.8, sparsifying to 75\n",
      "Epoch 13/1000\n",
      "157/157 [==============================] - 55s 352ms/step - loss: 0.2157 - accuracy: 0.9304 - val_loss: 0.7951 - val_accuracy: 0.7987\n",
      "Model performance reached 0.8, sparsifying to 80\n",
      "Epoch 14/1000\n",
      "157/157 [==============================] - 54s 346ms/step - loss: 0.1795 - accuracy: 0.9434 - val_loss: 0.8168 - val_accuracy: 0.7990\n",
      "Model performance reached 0.8, sparsifying to 85\n",
      "Epoch 15/1000\n",
      "157/157 [==============================] - 54s 345ms/step - loss: 0.1603 - accuracy: 0.9497 - val_loss: 0.8177 - val_accuracy: 0.7999\n",
      "Model performance reached 0.8, sparsifying to 90\n",
      "Epoch 16/1000\n",
      "157/157 [==============================] - 55s 348ms/step - loss: 0.1526 - accuracy: 0.9527 - val_loss: 0.8382 - val_accuracy: 0.8005\n",
      "Model performance reached 0.8, sparsifying to 95\n",
      "Epoch 17/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.1510 - accuracy: 0.9543 - val_loss: 0.8519 - val_accuracy: 0.7999\n",
      "Model cannot be sparsified further due to max sparsification parameter\n",
      "Epoch 18/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.1253 - accuracy: 0.9611 - val_loss: 0.8789 - val_accuracy: 0.8012\n",
      "Early stopping performance has not met threshold for 1 epochs\n",
      "Epoch 19/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.1151 - accuracy: 0.9648 - val_loss: 0.8752 - val_accuracy: 0.7979\n",
      "Early stopping performance has not met threshold for 2 epochs\n",
      "Epoch 20/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.1086 - accuracy: 0.9667 - val_loss: 0.8876 - val_accuracy: 0.7943\n",
      "Early stopping performance has not met threshold for 3 epochs\n",
      "Epoch 21/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.1152 - accuracy: 0.9658 - val_loss: 0.8994 - val_accuracy: 0.8010\n",
      "Early stopping performance has not met threshold for 4 epochs\n",
      "Epoch 22/1000\n",
      "157/157 [==============================] - 54s 344ms/step - loss: 0.0819 - accuracy: 0.9745 - val_loss: 0.9228 - val_accuracy: 0.8080\n",
      "Early stopping performance has not met threshold for 5 epochs\n",
      "Model performance has not met early stopping criteria. Stopping training\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x17a84b3a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the sparsification callback object\n",
    "callback = mann.utils.ActiveSparsification(\n",
    "    0.75,\n",
    "    starting_sparsification = 40,\n",
    "    sparsification_rate = 5\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs = 1000,\n",
    "    callbacks = [callback],\n",
    "    validation_split = 0.2,\n",
    "    batch_size = 256\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Functional)           (None, 1, 1, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 15,507,786\n",
      "Trainable params: 0\n",
      "Non-trainable params: 15,507,786\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Convert the model back\n",
    "model = mann.utils.remove_layer_masks(model)\n",
    "\n",
    "# Present the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: 0.7962\n"
     ]
    }
   ],
   "source": [
    "# Get the predictions on test data\n",
    "preds = model.predict(x_test).argmax(axis = 1)\n",
    "\n",
    "# Print the accuracy\n",
    "print(f'Model Accuracy: {(preds.flatten() == y_test.flatten()).sum().astype(int)/y_test.flatten().shape[0]}')\n",
    "\n",
    "# Save the model\n",
    "model.save('cifar_vgg16.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0671325c08d22fc44ce2e58aedbf8efae69ce5eb9c1911bbe321ecb24080d883"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
