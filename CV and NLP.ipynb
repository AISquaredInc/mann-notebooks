{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a70d6010",
   "metadata": {},
   "source": [
    "# Training a Single Model for Computer Vision and Natural Language Processing\n",
    "\n",
    "In this notebook, we train a single MANN model to perform both a computer vision task (image classification) as well as a natural language processing task (sentiment analysis).  For this notebook, we will use the MNIST Fashion dataset as well as the IMDB Sentiment Analysis dataset to train and test on.  Training will be done in a sequential manner, i.e. the network will first learn to perform image classification and then will learn to perform sentiment analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7adf8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the packages required for the experiment\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mann"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646127f8",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Data\n",
    "\n",
    "Our first step in this demonstration will be to load the data.  We are using the TensorFlow functions to download and/or load the datasets into memory.\n",
    "\n",
    "The `Fashion MNIST` dataset, which can be found at [this link](https://github.com/zalandoresearch/fashion-mnist), contains 60,000 grayscale training images of clothing items from 10 different classes, each 28 pixels high and 28 pixels wide.  The test set contains 10,000 grayscale images from the same 10 classes and with the same shape.  The only preprocessing we will be doing is dividing all pixel values by 255 to ensure all values fall in the interval [0, 1].\n",
    "\n",
    "The `IMDB Large Movie Review` dataset, which can be found at [this link](https://ai.stanford.edu/~amaas/data/sentiment/), contains 25,000 \"highly polar\" movie reviews for training and 25,000 reviews for testing.  When loaded through the TensorFlow function, these reviews are already converted into sequences of integers, where each integer corresponds to an individual word.  For our purposes, we will restrict the vocabulary to 10,000 words, so only the top 10,000 words will be represented, and any other words will be left as \"out of vocabulary\" (OOV).  Once that is complete, we will preprocess the inputs so that only the first 500 words in each review are considered, truncated and padded from the rear of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d50de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "(fashion_x_train, fashion_y_train), (fashion_x_test, fashion_y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(imdb_x_train, imdb_y_train), (imdb_x_test, imdb_y_test) = tf.keras.datasets.imdb.load_data(num_words = 10000)\n",
    "\n",
    "# Preprocess each of the input datasets. For the images, normalize each of the pixels to values between 0 and 1.\n",
    "# For the reviews, truncate and/or pad the lengths to 500 words each\n",
    "fashion_x_train = fashion_x_train/255\n",
    "fashion_x_test = fashion_x_test/255\n",
    "imdb_x_train = tf.keras.preprocessing.sequence.pad_sequences(imdb_x_train, maxlen = 500, padding = 'post', truncating = 'post')\n",
    "imdb_x_test = tf.keras.preprocessing.sequence.pad_sequences(imdb_x_test, maxlen = 500, padding = 'post', truncating = 'post')\n",
    "\n",
    "# Reshape the target data to having one column\n",
    "fashion_y_train = fashion_y_train.reshape(-1, 1)\n",
    "fashion_y_test = fashion_y_test.reshape(-1, 1)\n",
    "imdb_y_train = imdb_y_train.reshape(-1, 1)\n",
    "imdb_y_test = imdb_y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bcf698",
   "metadata": {},
   "source": [
    "## Create the Model\n",
    "\n",
    "Now that the data has been loaded and preprocessed, we can create the model.  Because of the different input shapes for our inputs, we have to develop some dedicated input regions within the model.  After data flows through those regions, which are pruned along with the rest of the network and include only a flatten and single fully connected layer for the fashion data and an embedding and fully connected layer for the IMDB data, the bulk of the network consists of shared layers.  \n",
    "\n",
    "In these shared layers, the training procedure identifies disjoint subsets of weights to dedicate to each individual task.  By isolating these highly-pruned subnetworks and representing the network weights across an extra, task-specific dimension, the network is able to learn multiple tasks in parallel or in sequence without exhibiting any interference between tasks.\n",
    "\n",
    "After passing through the shared layers, there are dedicated output layers for each task.  These are required because of the different output shapes between tasks - the image classification task differentiates between 10 different classes, whereas the sentiment analysis task performs binary classification to identify positive and negative reviews.\n",
    "\n",
    "After the model is instantiated, we utilize the `mask_model` function to perform masking (aka pruning) of the model.  This identifies the isolated subnetworks to perform each individual task and prepares the network for multitask training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc339a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 14:16:56.939539: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-04 14:16:56.939623: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 2)       20000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1000)         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense (MaskedDense)      (None, 512)          803840      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_1 (MaskedDense)    (None, 512)          1025024     flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense (MultiMasked [(None, 256), (None, 525312      masked_dense[0][0]               \n",
      "                                                                 masked_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_1 (MultiMask [(None, 256), (None, 263168      multi_masked_dense[0][0]         \n",
      "                                                                 multi_masked_dense[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_2 (MultiMask [(None, 256), (None, 263168      multi_masked_dense_1[0][0]       \n",
      "                                                                 multi_masked_dense_1[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_3 (MultiMask [(None, 256), (None, 263168      multi_masked_dense_2[0][0]       \n",
      "                                                                 multi_masked_dense_2[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_4 (MultiMask [(None, 256), (None, 263168      multi_masked_dense_3[0][0]       \n",
      "                                                                 multi_masked_dense_3[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_5 (MultiMask [(None, 256), (None, 263168      multi_masked_dense_4[0][0]       \n",
      "                                                                 multi_masked_dense_4[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "selector_layer (SelectorLayer)  (None, 256)          0           multi_masked_dense_5[0][0]       \n",
      "                                                                 multi_masked_dense_5[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "selector_layer_1 (SelectorLayer (None, 256)          0           multi_masked_dense_5[0][0]       \n",
      "                                                                 multi_masked_dense_5[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_2 (MaskedDense)    (None, 10)           5140        selector_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_3 (MaskedDense)    (None, 1)            514         selector_layer_1[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 3,695,670\n",
      "Trainable params: 1,857,835\n",
      "Non-trainable params: 1,837,835\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the input block for the fashion data, which includes an input layer, a flatten layer, and a masked dense layer\n",
    "fashion_input = tf.keras.layers.Input(fashion_x_train.shape[1:])\n",
    "fashion_flatten = tf.keras.layers.Flatten()(fashion_input)\n",
    "fashion_reshape = mann.layers.MaskedDense(512, activation = 'relu')(fashion_flatten)\n",
    "\n",
    "# Create the input block for the reviews data, which includes an input layer, an embedding layer, a flatten layer,\n",
    "# and a masked dense layer of equal output shape to the masked dense layer for the fashion input block\n",
    "imdb_input = tf.keras.layers.Input(imdb_x_train.shape[1:])\n",
    "imdb_embedding = tf.keras.layers.Embedding(10000, 2)(imdb_input)\n",
    "imdb_flatten = tf.keras.layers.Flatten()(imdb_embedding)\n",
    "imdb_reshape = mann.layers.MaskedDense(512, activation = 'relu')(imdb_flatten)\n",
    "\n",
    "# Now that the shapes align for each of the tasks, we can push the data through multitask layers\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')([fashion_reshape, imdb_reshape])\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')(x)\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')(x)\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')(x)\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')(x)\n",
    "x = mann.layers.MultiMaskedDense(256, activation = 'relu')(x)\n",
    "\n",
    "# Output block for the fashion data\n",
    "fashion_selector = mann.layers.SelectorLayer(0)(x)\n",
    "fashion_output = mann.layers.MaskedDense(10, activation = 'softmax')(fashion_selector)\n",
    "\n",
    "# Output block for the IMDB data\n",
    "imdb_selector = mann.layers.SelectorLayer(1)(x)\n",
    "imdb_output = mann.layers.MaskedDense(1, activation = 'sigmoid')(imdb_selector)\n",
    "\n",
    "# Instantiate the model and compile it\n",
    "model = tf.keras.models.Model([fashion_input, imdb_input], [fashion_output, imdb_output])\n",
    "model.compile(\n",
    "    loss = ['sparse_categorical_crossentropy', 'binary_crossentropy'],\n",
    "    metrics = 'accuracy',\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "\n",
    "# Mask (prune) the model and recompile for training\n",
    "model = mann.utils.mask_model(\n",
    "    model,\n",
    "    90,\n",
    "    x = [fashion_x_train[:1000], imdb_x_train[:1000]],\n",
    "    y = [fashion_y_train[:1000], imdb_y_train[:1000]]\n",
    ")\n",
    "model.compile(\n",
    "    loss = ['sparse_categorical_crossentropy', 'binary_crossentropy'],\n",
    "    metrics = 'accuracy',\n",
    "    optimizer = 'adam'\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a99c78",
   "metadata": {},
   "source": [
    "## Train the Model on the First Task\n",
    "\n",
    "After the model has been prepared, we can train it.  As stated previously, we are training the model in sequence on the individual tasks.  To do so, we compile the model so as to only optimize the loss for the specific task that is currently being trained, then pass dummy data to the task which is not being trained (in this case, empty-valued arrays).  The pruning previously done ensures only task-specific weights are being trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15c2027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 14:16:57.538176: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-04 14:16:57.965242: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-04 14:17:00.409247: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94/94 - 3s - loss: 1.7789 - masked_dense_2_loss: 1.7789 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.2887 - masked_dense_3_accuracy: 1.0000 - val_loss: 1.1820 - val_masked_dense_2_loss: 1.1820 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.4526 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 2/100\n",
      "94/94 - 2s - loss: 1.0293 - masked_dense_2_loss: 1.0293 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.5552 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.9519 - val_masked_dense_2_loss: 0.9519 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.5745 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 3/100\n",
      "94/94 - 2s - loss: 0.9279 - masked_dense_2_loss: 0.9279 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.5992 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.9037 - val_masked_dense_2_loss: 0.9037 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.5935 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 4/100\n",
      "94/94 - 2s - loss: 0.8789 - masked_dense_2_loss: 0.8789 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.6205 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.8478 - val_masked_dense_2_loss: 0.8478 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.6254 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 5/100\n",
      "94/94 - 2s - loss: 0.8212 - masked_dense_2_loss: 0.8212 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.6653 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.7861 - val_masked_dense_2_loss: 0.7861 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.6828 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "94/94 - 2s - loss: 0.7740 - masked_dense_2_loss: 0.7740 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7017 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.7426 - val_masked_dense_2_loss: 0.7426 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7117 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "94/94 - 2s - loss: 0.7236 - masked_dense_2_loss: 0.7236 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7297 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.7211 - val_masked_dense_2_loss: 0.7211 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7402 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "94/94 - 2s - loss: 0.6881 - masked_dense_2_loss: 0.6881 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7479 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.6739 - val_masked_dense_2_loss: 0.6739 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7592 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "94/94 - 2s - loss: 0.6549 - masked_dense_2_loss: 0.6549 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7626 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.6528 - val_masked_dense_2_loss: 0.6528 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7607 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "94/94 - 2s - loss: 0.6351 - masked_dense_2_loss: 0.6351 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7695 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.6570 - val_masked_dense_2_loss: 0.6570 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7587 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "94/94 - 2s - loss: 0.6125 - masked_dense_2_loss: 0.6125 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7771 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.6119 - val_masked_dense_2_loss: 0.6119 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7826 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "94/94 - 2s - loss: 0.5916 - masked_dense_2_loss: 0.5916 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7849 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5999 - val_masked_dense_2_loss: 0.5999 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7858 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "94/94 - 2s - loss: 0.5774 - masked_dense_2_loss: 0.5774 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7898 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5825 - val_masked_dense_2_loss: 0.5825 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7932 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "94/94 - 2s - loss: 0.5560 - masked_dense_2_loss: 0.5560 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.7988 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5701 - val_masked_dense_2_loss: 0.5701 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.7973 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "94/94 - 2s - loss: 0.5442 - masked_dense_2_loss: 0.5442 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8015 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5596 - val_masked_dense_2_loss: 0.5596 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8013 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "94/94 - 2s - loss: 0.5385 - masked_dense_2_loss: 0.5385 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8035 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5574 - val_masked_dense_2_loss: 0.5574 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8012 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "94/94 - 2s - loss: 0.5246 - masked_dense_2_loss: 0.5246 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8078 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5564 - val_masked_dense_2_loss: 0.5564 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8005 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "94/94 - 2s - loss: 0.5092 - masked_dense_2_loss: 0.5092 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8129 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5207 - val_masked_dense_2_loss: 0.5207 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8141 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "94/94 - 2s - loss: 0.4932 - masked_dense_2_loss: 0.4932 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8196 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5067 - val_masked_dense_2_loss: 0.5067 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8248 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "94/94 - 2s - loss: 0.4769 - masked_dense_2_loss: 0.4769 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8270 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.5090 - val_masked_dense_2_loss: 0.5090 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8217 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "94/94 - 2s - loss: 0.4565 - masked_dense_2_loss: 0.4565 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8340 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4813 - val_masked_dense_2_loss: 0.4813 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8380 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "94/94 - 2s - loss: 0.4311 - masked_dense_2_loss: 0.4311 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8478 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4734 - val_masked_dense_2_loss: 0.4734 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8378 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "94/94 - 2s - loss: 0.4198 - masked_dense_2_loss: 0.4198 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8534 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4533 - val_masked_dense_2_loss: 0.4533 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8446 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "94/94 - 2s - loss: 0.4072 - masked_dense_2_loss: 0.4072 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8577 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4519 - val_masked_dense_2_loss: 0.4519 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8480 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "94/94 - 2s - loss: 0.4097 - masked_dense_2_loss: 0.4097 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8564 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4417 - val_masked_dense_2_loss: 0.4417 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8497 - val_masked_dense_3_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100\n",
      "94/94 - 2s - loss: 0.3876 - masked_dense_2_loss: 0.3876 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8640 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4249 - val_masked_dense_2_loss: 0.4249 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8536 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "94/94 - 3s - loss: 0.3893 - masked_dense_2_loss: 0.3893 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8640 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4271 - val_masked_dense_2_loss: 0.4271 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8531 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "94/94 - 2s - loss: 0.3721 - masked_dense_2_loss: 0.3721 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8680 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4127 - val_masked_dense_2_loss: 0.4127 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8597 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "94/94 - 2s - loss: 0.3648 - masked_dense_2_loss: 0.3648 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8718 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4114 - val_masked_dense_2_loss: 0.4114 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8587 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "94/94 - 2s - loss: 0.3554 - masked_dense_2_loss: 0.3554 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8746 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4092 - val_masked_dense_2_loss: 0.4092 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8610 - val_masked_dense_3_accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "94/94 - 3s - loss: 0.3526 - masked_dense_2_loss: 0.3526 - masked_dense_3_loss: 0.6931 - masked_dense_2_accuracy: 0.8746 - masked_dense_3_accuracy: 1.0000 - val_loss: 0.4268 - val_masked_dense_2_loss: 0.4268 - val_masked_dense_3_loss: 0.6931 - val_masked_dense_2_accuracy: 0.8535 - val_masked_dense_3_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13f2974c0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell compiles the model for training task 1 (fashion) and trains the model for that task\n",
    "callback = tf.keras.callbacks.EarlyStopping(min_delta = 0.01, patience = 3, restore_best_weights = True)\n",
    "model.compile(\n",
    "    loss = ['sparse_categorical_crossentropy', 'binary_crossentropy'],\n",
    "    metrics = 'accuracy',\n",
    "    optimizer = 'adam',\n",
    "    loss_weights = [1, 0]\n",
    ")\n",
    "model.fit(\n",
    "    [fashion_x_train, np.zeros((fashion_x_train.shape[0], imdb_x_train.shape[1]))],\n",
    "    [fashion_y_train, np.zeros(fashion_y_train.shape)],\n",
    "    batch_size = 512,\n",
    "    epochs = 100,\n",
    "    callbacks = [callback],\n",
    "    validation_split = 0.2,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ff0fc3",
   "metadata": {},
   "source": [
    "# Train the Model on the Second Task\n",
    "\n",
    "Once the model has been trained on the first task, we repeat the process to train on the second task, this time compiling the model such that only the second task is trained for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543ad980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 14:18:05.828392: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-04 14:18:32.763094: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 28s - loss: 0.6932 - masked_dense_2_loss: 1.5219 - masked_dense_3_loss: 0.6932 - masked_dense_2_accuracy: 0.0000e+00 - masked_dense_3_accuracy: 0.4954 - val_loss: 0.6932 - val_masked_dense_2_loss: 1.5219 - val_masked_dense_3_loss: 0.6932 - val_masked_dense_2_accuracy: 0.0000e+00 - val_masked_dense_3_accuracy: 0.4938\n",
      "Epoch 2/100\n",
      "157/157 - 25s - loss: 0.6932 - masked_dense_2_loss: 1.5219 - masked_dense_3_loss: 0.6932 - masked_dense_2_accuracy: 0.0000e+00 - masked_dense_3_accuracy: 0.5016 - val_loss: 0.6932 - val_masked_dense_2_loss: 1.5219 - val_masked_dense_3_loss: 0.6932 - val_masked_dense_2_accuracy: 0.0000e+00 - val_masked_dense_3_accuracy: 0.4938\n",
      "Epoch 3/100\n",
      "157/157 - 24s - loss: 0.6932 - masked_dense_2_loss: 1.5219 - masked_dense_3_loss: 0.6932 - masked_dense_2_accuracy: 0.0000e+00 - masked_dense_3_accuracy: 0.5016 - val_loss: 0.6932 - val_masked_dense_2_loss: 1.5219 - val_masked_dense_3_loss: 0.6932 - val_masked_dense_2_accuracy: 0.0000e+00 - val_masked_dense_3_accuracy: 0.4938\n",
      "Epoch 4/100\n",
      "157/157 - 23s - loss: 0.6932 - masked_dense_2_loss: 1.5219 - masked_dense_3_loss: 0.6932 - masked_dense_2_accuracy: 0.0000e+00 - masked_dense_3_accuracy: 0.4984 - val_loss: 0.6932 - val_masked_dense_2_loss: 1.5219 - val_masked_dense_3_loss: 0.6932 - val_masked_dense_2_accuracy: 0.0000e+00 - val_masked_dense_3_accuracy: 0.4938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1596024f0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell compiles the model for training task 2 (IMDB) and trains the model for that task\n",
    "model.compile(\n",
    "    loss = ['sparse_categorical_crossentropy', 'binary_crossentropy'],\n",
    "    metrics = 'accuracy',\n",
    "    optimizer = 'adam',\n",
    "    loss_weights = [0, 1]\n",
    ")\n",
    "model.fit(\n",
    "    [np.zeros((imdb_x_train.shape[0],) + fashion_x_train.shape[1:]), imdb_x_train],\n",
    "    [np.zeros(imdb_y_train.shape[0]), imdb_y_train],\n",
    "    batch_size = 128,\n",
    "    epochs = 100,\n",
    "    callbacks = [callback],\n",
    "    validation_split = 0.2,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50841fee",
   "metadata": {},
   "source": [
    "## Remove masks\n",
    "\n",
    "After training is complete, we can perform the optional `remove_layer_masks` function, which removes the extra masking tensors utilized only during the training process.  This removal reduces the number of weights within the network, thus further optimizing it for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4393221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 2)       20000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1000)         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense (Dense)            (None, 512)          401920      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_1 (Dense)          (None, 512)          512512      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense (MultiDense) [(None, 256), (None, 262656      masked_dense[0][0]               \n",
      "                                                                 masked_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_1 (MultiDens [(None, 256), (None, 131584      multi_masked_dense[0][0]         \n",
      "                                                                 multi_masked_dense[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_2 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_1[0][0]       \n",
      "                                                                 multi_masked_dense_1[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_3 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_2[0][0]       \n",
      "                                                                 multi_masked_dense_2[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_4 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_3[0][0]       \n",
      "                                                                 multi_masked_dense_3[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_5 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_4[0][0]       \n",
      "                                                                 multi_masked_dense_4[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "selector_layer (SelectorLayer)  (None, 256)          0           multi_masked_dense_5[0][0]       \n",
      "                                                                 multi_masked_dense_5[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "selector_layer_1 (SelectorLayer (None, 256)          0           multi_masked_dense_5[0][0]       \n",
      "                                                                 multi_masked_dense_5[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_2 (Dense)          (None, 10)           2570        selector_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_3 (Dense)          (None, 1)            257         selector_layer_1[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,857,835\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,857,835\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simplified_model = mann.utils.remove_layer_masks(model)\n",
    "simplified_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7de341",
   "metadata": {},
   "source": [
    "## Get predictions and Report Performance\n",
    "\n",
    "Lastly, we retrieve the predictions on the test data from the model and report the performance of the model on each of the individual tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eb3fc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-04 14:19:44.765422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-01-04 14:19:45.954788: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "fashion_preds = simplified_model.predict([fashion_x_test, np.zeros((fashion_x_test.shape[0], imdb_x_test.shape[1]))])[0].argmax(axis = 1)\n",
    "imdb_preds = (simplified_model.predict([np.zeros((imdb_x_test.shape[0],) + fashion_x_test.shape[1:]), imdb_x_test])[1].flatten() >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f249a5eb",
   "metadata": {},
   "source": [
    "## Fashion Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "763c5443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fashion Test Performance:\n",
      "\n",
      "\n",
      "[[848   0  10  38   2   0  90   0  12   0]\n",
      " [  3 951   3  37   3   0   2   0   1   0]\n",
      " [ 19   1 746   7 118   0 104   0   5   0]\n",
      " [ 46   7  14 861  36   0  32   0   4   0]\n",
      " [  0   0 115  24 789   0  69   0   3   0]\n",
      " [  0   0   0   0   0 956   0  16   7  21]\n",
      " [221   0 127  34  97   0 500   0  21   0]\n",
      " [  0   0   0   0   0  24   0 921   0  55]\n",
      " [  1   0   3   2   2   8  28   4 951   1]\n",
      " [  0   0   0   0   0  20   0  32   1 947]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.85      0.79      1000\n",
      "           1       0.99      0.95      0.97      1000\n",
      "           2       0.73      0.75      0.74      1000\n",
      "           3       0.86      0.86      0.86      1000\n",
      "           4       0.75      0.79      0.77      1000\n",
      "           5       0.95      0.96      0.95      1000\n",
      "           6       0.61      0.50      0.55      1000\n",
      "           7       0.95      0.92      0.93      1000\n",
      "           8       0.95      0.95      0.95      1000\n",
      "           9       0.92      0.95      0.94      1000\n",
      "\n",
      "    accuracy                           0.85     10000\n",
      "   macro avg       0.85      0.85      0.85     10000\n",
      "weighted avg       0.85      0.85      0.85     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Fashion Test Performance:')\n",
    "print('\\n')\n",
    "print(confusion_matrix(fashion_y_test, fashion_preds))\n",
    "print('\\n')\n",
    "print(classification_report(fashion_y_test, fashion_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b26936",
   "metadata": {},
   "source": [
    "## IMDB Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "277e429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB Test Performance:\n",
      "\n",
      "\n",
      "[[    0 12500]\n",
      " [    0 12500]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     12500\n",
      "           1       0.50      1.00      0.67     12500\n",
      "\n",
      "    accuracy                           0.50     25000\n",
      "   macro avg       0.25      0.50      0.33     25000\n",
      "weighted avg       0.25      0.50      0.33     25000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwrenn4/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jwrenn4/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/jwrenn4/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print('IMDB Test Performance:')\n",
    "print('\\n')\n",
    "print((confusion_matrix(imdb_y_test, imdb_preds)))\n",
    "print('\\n')\n",
    "print(classification_report(imdb_y_test, imdb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71a825",
   "metadata": {},
   "source": [
    "## Save and load the model\n",
    "\n",
    "An important part of being able to deploy models is the ability to save and load the models to disk.  We provide extra utilities to help save and load these models consistent with the `keras` API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fc569a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 500)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            [(None, 28, 28)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 500, 2)       20000       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 784)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 1000)         0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense (Dense)            (None, 512)          401920      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_1 (Dense)          (None, 512)          512512      flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense (MultiDense) [(None, 256), (None, 262656      masked_dense[0][0]               \n",
      "                                                                 masked_dense_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_1 (MultiDens [(None, 256), (None, 131584      multi_masked_dense[0][0]         \n",
      "                                                                 multi_masked_dense[0][1]         \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_2 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_1[0][0]       \n",
      "                                                                 multi_masked_dense_1[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_3 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_2[0][0]       \n",
      "                                                                 multi_masked_dense_2[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_4 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_3[0][0]       \n",
      "                                                                 multi_masked_dense_3[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "multi_masked_dense_5 (MultiDens [(None, 256), (None, 131584      multi_masked_dense_4[0][0]       \n",
      "                                                                 multi_masked_dense_4[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "selector_layer (SelectorLayer)  (None, 256)          0           multi_masked_dense_5[0][0]       \n",
      "                                                                 multi_masked_dense_5[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "selector_layer_1 (SelectorLayer (None, 256)          0           multi_masked_dense_5[0][0]       \n",
      "                                                                 multi_masked_dense_5[0][1]       \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_2 (Dense)          (None, 10)           2570        selector_layer[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "masked_dense_3 (Dense)          (None, 1)            257         selector_layer_1[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 1,857,835\n",
      "Trainable params: 0\n",
      "Non-trainable params: 1,857,835\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "simplified_model.save('cv_and_nlp_model.h5')\n",
    "loaded_model = tf.keras.models.load_model('cv_and_nlp_model.h5', custom_objects = mann.utils.get_custom_objects())\n",
    "loaded_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python397jvsc74a57bd00671325c08d22fc44ce2e58aedbf8efae69ce5eb9c1911bbe321ecb24080d883"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
